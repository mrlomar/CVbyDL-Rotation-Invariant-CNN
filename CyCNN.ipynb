{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cylindrical CNN for Beer Cap Classification\n",
    "In this notebook, we try to develop a **Convolution Neural Network** that can classify randomly rotated beer caps while training on limited data. We do this by trying to make the network **invariant to rotation** to reduce the amount of samples needed for training. Our thought behind this is that a network that inherently comprehends rotation will need less training data to obtain reasonable results than a traditional CNN that needs to learn the rotations. To achieve this invariance, we implement the theory published in the paper [CyCNN: A Rotation Invariant CNN using Polar Mapping and Cylindrical Convolution Layers](https://arxiv.org/pdf/2007.10588.pdf). First we apply the theory to the MNIST dataset to assess whether it works as intended and secondly we apply the theory to our own generated data set to assess the viability of our approach.\n",
    "\n",
    "## Creating CyCNN\n",
    "Making the network invariant to rotations consists of two steps, namely: **(1)** Transforming the input to polar coordinates and **(2)** using Cylindrical Convolutional Layers. Both of these steps are discussed in their respective subsections.\n",
    "\n",
    "| Normal Coordinates | Polar Coordinates | Circular Padding |\n",
    "| :----------------: | :---------------: | :--------------: |\n",
    "| <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/normal_rotations.gif?raw=true\" width=\"400\"> | <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/polar_rotations.gif?raw=true\" width=\"400\"> | <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/padded_rotations.gif?raw=true\" width=\"400\"> |\n",
    "\n",
    "### Polar Coordinates\n",
    "The idea of polar coordinates is to express locations in the image as $(r, \\phi)$ instead of $(x, y)$, where $r$ is the distance to the origin and $\\phi$ is the angle. Because one of the coordinates includes the rotation in the original image, using polar coordinates transforms rotations in the original space to translations in polar space. Since CNN's *should* be translation invariant, this would in theory make the network invariant to rotations in the original space. But since there is no free lunch in computer science, using this does make the network less robust to translations in the original space.\n",
    "\n",
    "A visualisation of the process discussed in this subsection can be found in the first and second row of the table above.\n",
    "\n",
    "### Cylindrical Convolutional Layers\n",
    "The next step to making the CNN invariant to rotations is to implement Cylindrical Convolutions Layers. While this might sound intimidating, it is actually rather simple. To make the convolutional layer cylindrical, one only has to use a special type of padding. When using polar coordinates the $\\phi$ coordinate represents the rotation, this means that the top of the image connects to the bottom of the image. To communicate this information to the CNN the padding on the bottom should continue with the pixels found at the top of the image. For the $r$ coordinate there is no such relation. Because of this on the x-axis *Zero padding* is used.\n",
    "\n",
    "A visualisation of cylindrical padding can be found in the second and third row of the table above.\n",
    "\n",
    "## Beer Cap Dataset\n",
    "### Photo acquisition\n",
    "To create our beer cap dataset, a setup with a Raspberry Pi with Pi Camera was used. In this setup, a beer cap enters on top, when detected by a sensor, the first servo will let it through, then the beer cap enters a dark space which is lid by LEDs for consistent lighting conditions. There it is photographed, after which a second servo will let it pass and then it drops down in a big container. The first servo prevents a second beer cap from entering while another beer cap is in process. The setup also includes a 7-segment display that shows the total counted beer caps. We had some struggles with getting good lighting conditions since we wanted good and consistent photos. Photos taken in the middle of the day looked way better than later on the day. Furthermore, the direction of the light mattered for shadows a lot. We solved this by using LEDs and preventing most other light in the picture. Because the plexiglass in front of the beer caps reflects the LEDs light, this was also a challenge which we solve by careful placement of the LEDs, specific camera settings and accepting some reflections.\n",
    "\n",
    "|      |      |      |\n",
    "| :--: | :--: | :--: |\n",
    "| <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/BCC.jpeg?raw=true\" width=\"225\"> | <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/BCC%20met%20bak.jpeg?raw=true\" width=\"163\"> | <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/beercap.png?raw=true\" width=\"400\"> |\n",
    "\n",
    "### Data augmentation\n",
    "We wanted good and consistent images so we could increase the size of the dataset by data augmentation. We first cropped the pictures, then resized them to 32 by 32 pixels. We then included those images and several randomly rotated variants of those images in the dataset. The idea being that bottle caps that would enter already have a random rotation, and by randomly rotating images, we simulated more entries of the same brand.\n",
    "\n",
    "## Comparison MNIST\n",
    "### Network Architecture\n",
    "To evaluate our CyCNN on the MNIST dataset, the architecture seen below was used both for the CNN and CyCNN. Between each cube shown in the figure below there is a convolutional layer which applies the following steps to the input: **(1)** Apply cylindrical padding, **(2)** Apply a 3x3 convolution, **(3)** Apply the ReLu function and **(4)** Apply 2x2 max-pooling. The (Cy)CNN is then connected to a fully connected neural network to classify the input. When using the CyCNN model, there occurs a polar transformation between the input and the first convolution layer.\n",
    "![](https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/MNIST_arch.png?raw=true)\n",
    "\n",
    "### Experiment\n",
    "To assess the effectiveness of using the CyCNN rather than the traditional CNN, we compare the results of 4 models on non-rotated and randomly rotated images. The models we evaluate are the following:\n",
    "- **CyCNN<sup>R</sup>** - This model uses polar coordinates and cylindrical convolutional layers, but also includes an extra step. When an input is given to the network, CyCNN<sup>R</sup> first randomly rotates the image before feeding it to its learned network. This means that while training the model will see and learn rotations of the original data.\n",
    "\n",
    "- **CyCNN** - This model uses polar coordinates and cylindrical convolutional layers, but does not randomly rotate the images. This means that when the model is evaluated on rotated images, it will never have seen these rotations before. Any improvements over the traditional CNN will be purely due to the use of polar coordinates and cylindrical convolutional layers.\n",
    "\n",
    "- **CNN<sup>R</sup>** - This model is a standard CNN, but it also randomly rotated the input images before feeding it into the network. This approach could theoretically allow the CNN to learn the rotations on its own.\n",
    "\n",
    "- **CNN** - This model is a standard CNN that does not randomly rotate the images. Therefore, during testing it will never have seen these rotations before.\n",
    "\n",
    "To compare the models, each model is trained for 2 epochs. In the first epoch the learning rate is set to $0.001$ and in the second epoch the learning rate is set to $0.0001$.\n",
    "\n",
    "### Results\n",
    "The results of the experiment discussed above are shown in the table below.\n",
    "\n",
    "| Model | Normal Accuracy | Rotated Accuracy |\n",
    "| :---: | :-------------: | :--------------: |\n",
    "|CyCNN<sup>R</sup>|92%|**91%**|\n",
    "|CyCNN            |94%|72%|\n",
    "|CNN<sup>R</sup>  |88%|88%|\n",
    "|CNN              |**97%**|39%|\n",
    "\n",
    "As you can see, **CyCNN<sup>R</sup>** achieves the highest accuracy on the randomly rotated data. While the traditional CNN achieves the highest accuracy on the non-rotated data, its accuracy tanks when the images are randomly rotated (as expected). Comparing the CyCNN to the CNN, we can see that CyCNN inherently is more invariant to rotations, as it achieves an accuracy of 72% rather than 39% on the randomly rotated data. Overal, we can see that using a CyCNN<sup>R</sup> seems to be the best approach for our use case.\n",
    "\n",
    "Lastly, an interesting thing to note is the distinction between 6's and 9's when the data is randomly rotated. In theory, a network this is invariant to rotation should be able to distinguish a 6 from an upside-down 9 and vice-versa. A network that is not invariant to rotations would not be able to do this. To investigate this, we look at the prediction distribution for 6's and 9's for the CyCNN model. The results are shown below.\n",
    "\n",
    "| CyCNN 6 predictions | CyCNN 9 predictions |\n",
    "| :-----------------: | :------------------: | \n",
    "| <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/sixes.png?raw=true\" width=\"400\"> | <img src=\"https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/nines.png?raw=true\" width=\"400\"> |\n",
    "\n",
    "We can see that while the CyCNN is not able to distinguish between the two classes fully, it is able to correctly classify both classes the majority of the time. We can also see that strangely enough the network has more difficulty with distinguishing between a 9 and a 5 than between a 9 and a 6. This could be because when using polar coordinates a 5 might be more similar to a 9 than a 6 is to a 9.\n",
    "\n",
    "## Comparison Beer caps\n",
    "### Network Architecture\n",
    "To evaluate our CyCNN on the CAP dataset, the architecture seen below was used both for the CNN and CyCNN. Between each cube shown in the figure below there is a convolutional layer which applies the following steps to the input: **(1)** Apply cylindrical padding, **(2)** Apply a 3x3 convolution, **(3)** Apply the ReLu function and **(4)** Apply 2x2 max-pooling. The (Cy)CNN is then connected to a fully connected neural network to classify the input. When using the CyCNN model, there occurs a polar transformation between the input and the first convolution layer.\n",
    "![](https://github.com/mrlomar/CVbyDL-Rotation-Invariant-CNN/blob/main/images/CAP_arch.png?raw=true)\n",
    "\n",
    "### Experiment\n",
    "To assess the effectiveness of the CyCNN on the beer cap dataset, we first train on the full dataset where we use 80% for training and 20% for testing. The models, CyCNN<sup>R</sup>, CyCNN, CNN<sup>R</sup> and CNN, are each trained 10 epochs starting with a learning rate of 0.001 and after epoch 5 a learning rate of 0.0001 with a momentum of 0.9.\n",
    "\n",
    "We trained for different (lesser) amounts of training data to see if the CyCNN requires less data than the CNN. We used 20% as test data, then decreasingly used less data (80%, 60%, 40%, 20%, 10%) of the total data as train data. The remaining data was not used.\n",
    "\n",
    "### Results\n",
    "The results of the experiment discussed above are shown in the table below. In each cell the accuracy on the test set followed by the randomly rotated test set is shown.\n",
    "\n",
    "| Model \\ % data used for training | 80%             | 60%             | 40%             | 20%             | 10%         |\n",
    "| :------------------------------: | :-------------: | :-------------: | :-------------: | :-------------: | :---------: |\n",
    "|CyCNN<sup>R</sup>                 | 98%/**99%**     | **99%**/**99%** | 98%/98%         | 93%/94%         | **94%**/94% |\n",
    "|CyCNN                             | **99%**/**99%** | **99%**/98%     | **99%**/**99%** | **97%**/**97%** | 93%/**95%** |\n",
    "|CNN<sup>R</sup>                   | 96%/96%         | 95%/95%         | 94%/94%         | 92%/92%         | 80%/82%     | \n",
    "|CNN                               | 98%/93%         | 96%/90%         | 88%/82%         | 91%/87%         | 79%/81%     |\n",
    "\n",
    "\n",
    "As you can see in the table, the CyCNN overall performs the best. On this dataset we expected (almost) no difference between the CyCNN<sup>R</sup> and the CyCNN because the beer caps already have lots of different rotations.  When there is less data to train on, the difference between the CyCNN and the CNN increased, which supports our hypothesis.\n",
    "\n",
    "## Discussion\n",
    "During our experiment, we identified a three main issues. The first one being that the we did not use K-fold cross validation to make our experiments more robust. We made this choice mainly due to time and resource limitations.\n",
    "\n",
    "Secondly, training epochs were limited due to time restrictions. This could influence the results if CyCNN is able to learn to a higher accuracy than a traditional CNN, but we can not confirm this.\n",
    "\n",
    "Lastly, during training on the CAP dataset, the network sometimes had a sort of restart and would not recover from it. This meant that sometimes CyCNN or CNN would achieve terrible results. We haven't yet been able to explain this phenomenon.\n",
    "\n",
    "## Code\n",
    "Below, all the code for creating a CyCNN and running it on MNIST and our custom CAP dataset can be found.\n",
    "### Dependencies\n",
    "\n",
    "First, all dependencies are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\users\\mdesc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# -------\n",
    "# IMPORTS\n",
    "# -------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import WeightedRandomSampler, SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import random, math\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters and seed\n",
    "\n",
    "Then all global parameters are set as well as a global seed (with seed function). The seed is usefull for reproducability and to make sure that the train and test split won't overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameter\n",
    "NUM_CLASSES_CAP = 4\n",
    "\n",
    "# Seed for reproducability\n",
    "SEED = 69429\n",
    "\n",
    "# Function to (re)set the seed\n",
    "def set_seed():\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Function needed setting seed for the torch Dataloader\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(SEED) + worker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "Here the raw images of the beer caps are transformed in a dataset by first cropping, then resizing and finally rotation the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# BOTTLE CAP DATA AUGMENTATION\n",
    "# ----------------------------\n",
    "\n",
    "set_seed() # reset seed\n",
    "\n",
    "SIZE = 32\n",
    "AUGMENT_DATA = False\n",
    "ROTATIONS = 4\n",
    "\n",
    "if AUGMENT_DATA:\n",
    "    cap_data = \"./data/CAPS_2/\"\n",
    "    new_cap_data = \"./data/CAPS\" + str(SIZE) + \"/\"\n",
    "    classes = range(NUM_CLASSES_CAP)\n",
    "\n",
    "    for c in classes:\n",
    "        new_dir = new_cap_data + str(c) + '/'\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.makedirs(new_dir)\n",
    "        for filename in os.listdir(cap_data + str(c) + '/'):\n",
    "            if filename.endswith(\".png\"):\n",
    "                file = cap_data + str(c) + '/' + filename\n",
    "                img = cv.imread(file)\n",
    "                # Crop image to remove 32 pixels on the left and 16 pixels on the right, 24 top, 24 bottom\n",
    "                img = img[32:256-16, 24:256-24]\n",
    "                # Resize image\n",
    "                img = cv.resize(img, (SIZE, SIZE))\n",
    "                cv.imwrite(new_cap_data + str(c) + '/' + filename, img)\n",
    "                # save ROTATIONS rotations of the data\n",
    "                for r in range(ROTATIONS):\n",
    "                    M = cv.getRotationMatrix2D((SIZE // 2, SIZE // 2), random.uniform(0, 1) * 360, 1.0)\n",
    "                    rotated = cv.warpAffine(img, M, (SIZE, SIZE))\n",
    "                    cv.imwrite(new_cap_data + str(c) + '/r' + str(r) + '_' + filename, rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function from the original paper\n",
    "\n",
    "We reused 2 functions from the original paper. The polar transformation as well as the random rotation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------\n",
    "# FUNCTIONS RETRIEVED FROM https://github.com/mcrl/CyCNN/blob/master/cycnn/image_transforms.py\n",
    "#\n",
    "# For this section of code:\n",
    "#     Copyright (c) 2020 Seoul National University.\n",
    "#     All rights reserved.\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "def polar_transform(images, transform_type='linearpolar'):\n",
    "    \"\"\"\n",
    "    This function takes multiple images, and apply polar coordinate conversion to it.\n",
    "    \"\"\"\n",
    "    results = images.clone()\n",
    "    \n",
    "    (N, C, H, W) = results.shape\n",
    "\n",
    "    for i in range(results.shape[0]):\n",
    "\n",
    "        img = results[i].numpy()  # [C,H,W]\n",
    "        img = np.transpose(img, (1, 2, 0))  # [H,W,C]\n",
    "\n",
    "        if transform_type == 'logpolar':\n",
    "            img = cv.logPolar(img, (H // 2, W // 2), W / math.log(W / 2), cv.WARP_FILL_OUTLIERS).reshape(H, W, C)\n",
    "        elif transform_type == 'linearpolar':\n",
    "            img = cv.linearPolar(img, (H // 2, W // 2), W / 2, cv.WARP_FILL_OUTLIERS).reshape(H, W, C)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        results[i] = torch.from_numpy(img)\n",
    "\n",
    "    return results\n",
    "\n",
    "def random_rotate(images):\n",
    "    \"\"\"\n",
    "    This function takes multiple images, and rotate each image by a random angle [0, 360)\n",
    "    \"\"\"\n",
    "    new_images = []\n",
    "\n",
    "    (N, C, H, W) = images.shape\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        img = images[i].numpy()  # [C,H,W]\n",
    "\n",
    "        img = np.transpose(img, (1, 2, 0))  # [H,W,C]\n",
    "\n",
    "        d = random.randint(0, 360 - 1)\n",
    "\n",
    "        M = cv.getRotationMatrix2D((H // 2, W // 2), d, 1.0)\n",
    "        img_rot = cv.warpAffine(img, M, (H, W)).reshape(H, W, C)\n",
    "\n",
    "        img_rot = np.transpose(img_rot, (2, 0, 1))  # [C,H,W]\n",
    "        new_images.append(img_rot)\n",
    "\n",
    "    new_images = torch.from_numpy(np.stack(new_images, axis=0))\n",
    "\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset\n",
    "\n",
    "Downloads and loads MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# DOWNLOADING AND LOADING MNIST DATASET\n",
    "# -------------------------------------\n",
    "\n",
    "data_dir='./data'\n",
    "\n",
    "MNIST_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Resize((32,32), torchvision.transforms.InterpolationMode.BILINEAR)\n",
    "    ])\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=MNIST_transform)\n",
    "MNIST_test = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=MNIST_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Beer Cap dataset\n",
    "\n",
    "Loads the augmented data and applies a normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP data loaded\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# LOADING THE CAPS DATASET\n",
    "# ------------------------\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Images should be normalized, which means we need to calculate/approximate the means and standard deviations\n",
    "APPROXIMATION_SAMPLES = 300\n",
    "CAP_DATA_FOLDER = \"./data/CAPS32/\"\n",
    "\n",
    "R = []\n",
    "G = []\n",
    "B = []\n",
    "\n",
    "for c in range(NUM_CLASSES_CAP):\n",
    "    sample = 0\n",
    "    for filename in os.listdir(CAP_DATA_FOLDER + str(c) + \"/\"):\n",
    "        if sample == APPROXIMATION_SAMPLES:\n",
    "            break\n",
    "        if filename.endswith(\".png\"):\n",
    "            file = CAP_DATA_FOLDER + str(c) + '/' + filename\n",
    "            img = cv.imread(file)\n",
    "            for x in img:\n",
    "                for pix in x:\n",
    "                    R.append(pix[0])\n",
    "                    G.append(pix[1])\n",
    "                    B.append(pix[2])\n",
    "            sample += 1\n",
    "            \n",
    "R = np.multiply(R, 1/255)\n",
    "G = np.multiply(G, 1/255)\n",
    "B = np.multiply(B, 1/255)\n",
    "\n",
    "R_avg = np.mean(R); R_std = np.std(R)\n",
    "G_avg = np.mean(G); G_std = np.std(G)\n",
    "B_avg = np.mean(B); B_std = np.std(B)\n",
    "\n",
    "CAP_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[R_avg, G_avg, B_avg],\n",
    "            std=[R_std, G_std, B_std],\n",
    "        ),\n",
    "        transforms.Resize((32,32), torchvision.transforms.InterpolationMode.BILINEAR)\n",
    "    ])\n",
    "\n",
    "\n",
    "CAP_data = torchvision.datasets.ImageFolder(root=CAP_DATA_FOLDER, transform=CAP_transform)\n",
    "\n",
    "print(\"CAP data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class balancing\n",
    "\n",
    "This function returns a weighted sampler to solve the class imbalance in the beer cap dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weightedSampler(data, classes):\n",
    "    data_size = len(data)\n",
    "    num_classes = len(classes)\n",
    "    class_weights = {}\n",
    "    for i in range(num_classes):\n",
    "        class_weights[classes[i]] = 0\n",
    "\n",
    "    for i in range(data_size):\n",
    "        img, label = data[i]\n",
    "        class_weights[classes[label]] += 1\n",
    "        \n",
    "    min_num_samples = sys.maxsize\n",
    "    \n",
    "    for label, count in class_weights.items():\n",
    "        min_num_samples = min(min_num_samples, count)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_weights[classes[i]] = min_num_samples / class_weights[classes[i]]\n",
    "\n",
    "    sample_weights = [0] * data_size\n",
    "\n",
    "\n",
    "    for idx, (_, label) in enumerate(data):\n",
    "        sample_weights[idx] = class_weights[str(label)]\n",
    "    \n",
    "    g_cpu = torch.Generator()\n",
    "    g_cpu.manual_seed(SEED)\n",
    "\n",
    "    return WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True, generator=g_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "This function returns 2 dataloaders for the train and test data for any train/test distribution. This distribution does not have to use all the data. When `test_propotion` + `train_proportion` < 1.0 the remaining data is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, train_proportion=0.8, test_proportion=0.2):\n",
    "    '''\n",
    "    Returns a train- and test-loader based on the name of the data set\n",
    "    The option for `dataset` are: `MNIST` and `CAP`\n",
    "    '''\n",
    "    if dataset == 'MNIST':\n",
    "        return torch.utils.data.DataLoader(MNIST_train), torch.utils.data.DataLoader(MNIST_test)\n",
    "    if dataset == 'CAP':\n",
    "        \n",
    "        data_size = len(CAP_data)\n",
    "        test_size = round(test_proportion * data_size)\n",
    "        train_size = min(data_size - test_size, round(train_proportion * data_size))\n",
    "        remaining_size = data_size - test_size - train_size\n",
    "\n",
    "        CAP_data_train, CAP_data_test, _ = torch.utils.data.random_split(CAP_data, [train_size, test_size, remaining_size])\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(CAP_data_train, sampler=get_weightedSampler(CAP_data_train, CAP_data.classes), batch_size=1,num_workers=0, worker_init_fn=_init_fn)\n",
    "        test_loader = torch.utils.data.DataLoader(CAP_data_test, batch_size=1,num_workers=0, worker_init_fn=_init_fn)\n",
    "        return train_loader, test_loader\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polar transformation and Padding Example\n",
    "\n",
    "Here, a handwritten '7' is transfromed to its polar coordinates. This is done another time for a rotated version of the image, which results in a swift in the polar coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data label: tensor(7) \n",
      "Original Data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original => Polar\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotated Original\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotated Original => Polar\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyclic Padding\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# EXAMPLE OF POLAR TRANSFORMATION AND PADDING\n",
    "# -------------------------------------------\n",
    "\n",
    "_, example_data = load_data('MNIST')\n",
    "example_iter = iter(example_data)\n",
    "\n",
    "for i in range(1):\n",
    "    image, label = example_iter.next()\n",
    "    print('Data label:', label[0], '\\nOriginal Data')\n",
    "    plt.imshow(np.transpose(image[0].numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    print('Original => Polar')\n",
    "    new_image = image.clone()\n",
    "    new_image = polar_transform(new_image)\n",
    "    plt.imshow(np.transpose(new_image[0].numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    print('Rotated Original')\n",
    "    image = random_rotate(image)\n",
    "    plt.imshow(np.transpose(image[0].numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    print('Rotated Original => Polar')\n",
    "    new_image = image.clone()\n",
    "    new_image = polar_transform(new_image)\n",
    "    plt.imshow(np.transpose(new_image[0].numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    print('Cyclic Padding')\n",
    "    N = 5\n",
    "    new_image = F.pad(new_image, (0, 0, N, N), mode='circular')\n",
    "    new_image = F.pad(new_image, (N, N, 0, 0), mode='constant')\n",
    "    plt.imshow(np.transpose(new_image[0].numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cyCNN model\n",
    "\n",
    "Defines the model for both the MNIST and beer cap dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------\n",
    "# DEFINE CyCNN\n",
    "# ------------\n",
    "\n",
    "set_seed()\n",
    "\n",
    "class CyNet(nn.Module):\n",
    "    def __init__(self, layers=None, data='MNIST', random_rotate=False):\n",
    "        '''\n",
    "        `layers` can be passed to create a 'custom' CyCNN.\n",
    "        layers should be a tuple (C, L), with:\n",
    "            C => a list containing a triplet (INPUT_CHANNELS, OUTPUT_CHANNELS, KERNEL_SIZE) for each convolutional layer\n",
    "            L => a list containing a tuple (INPUT_CHANNELS, OUTPUT_CHANNELS) for each linear layer\n",
    "        \n",
    "        `data` can be passed to indicate which default network to use.\n",
    "        \n",
    "        `random_rotate` can be used to make the network generalize better.\n",
    "        However, there are some data requirements for it to work, which is why it is disabled by default.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create Cyclic padding\n",
    "        self.padVer = lambda x: F.pad(x, (0, 0, 1, 1), mode='circular')\n",
    "        self.padHor = lambda x: F.pad(x, (1, 1, 0, 0), mode='constant')\n",
    "\n",
    "        # Define the pooling used\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Create lists used for the convolutional- and linear layers.\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.fcs = nn.ModuleList()\n",
    "        self.view = -1\n",
    "        \n",
    "        self.random_rotate = random_rotate\n",
    "        \n",
    "        if layers is None:\n",
    "            # If no layers are passed, create the default network\n",
    "            # The default network is dependent on the data set\n",
    "            if data == 'MNIST':\n",
    "                # Default network for MNIST dataset\n",
    "                self.convs.append(nn.Conv2d(1, 3, 3))\n",
    "                self.convs.append(nn.Conv2d(3, 8, 3))\n",
    "                self.convs.append(nn.Conv2d(8, 16, 3))\n",
    "                self.convs.append(nn.Conv2d(16, 32, 3))\n",
    "                self.convs.append(nn.Conv2d(32, 64, 3))\n",
    "\n",
    "                self.view = 64\n",
    "\n",
    "                self.fcs.append(nn.Linear(64, 32))\n",
    "                self.fcs.append(nn.Linear(32, 24))\n",
    "                self.fcs.append(nn.Linear(24, 10))\n",
    "\n",
    "            if data == 'CAP':\n",
    "                # Default network for CAP dataset\n",
    "                self.convs.append(nn.Conv2d(3, 4, 3))\n",
    "                self.convs.append(nn.Conv2d(4, 6, 3))\n",
    "                self.convs.append(nn.Conv2d(6, 12, 3))\n",
    "                self.convs.append(nn.Conv2d(12, 16, 3))\n",
    "                self.convs.append(nn.Conv2d(16, 24, 3))\n",
    "\n",
    "                self.view = 24\n",
    "\n",
    "                self.fcs.append(nn.Linear(24, 12))\n",
    "                self.fcs.append(nn.Linear(12, NUM_CLASSES_CAP))\n",
    "        else:\n",
    "            # Parse the given layers\n",
    "            for cl in layers[0]:\n",
    "                self.convs.append(nn.Conv2d(cl[0], cl[1], cl[2]))\n",
    "            for fcl in layers[1]:\n",
    "                self.fcs.append(nn.Linear(fcl[0], fcl[1]))\n",
    "            self.view = layers[1][0][0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.random_rotate:\n",
    "            # Randomly rotate the input data is the option is enabled.\n",
    "            x = random_rotate(x)\n",
    "        # Perform polar transformation on the input\n",
    "        x = polar_transform(x)\n",
    "        # Run the sample through all convolutional layers\n",
    "        for conv in self.convs:\n",
    "            x = self.pool(F.relu(conv(self.padVer(self.padHor(x)))))\n",
    "        # Run the result from the convolution through the linear layers\n",
    "        x = x.view(-1, self.view)\n",
    "        for l in self.fcs[:-1]:\n",
    "            x = F.relu(l(x))\n",
    "        # Don't use the relu for the last layer\n",
    "        x = self.fcs[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CNN model\n",
    "\n",
    "Defines the model for both the MNIST and beer cap dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# DEFINE EQUIVALENT CNN FOR COMPARISON\n",
    "# ------------------------------------\n",
    "\n",
    "set_seed()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, layers=None, data='MNIST', random_rotate=False):\n",
    "        '''\n",
    "        `layers` can be passed to create a 'custom' CNN.\n",
    "        layers should be a tuple (C, L), with:\n",
    "            C => a list containing a triplet (INPUT_CHANNELS, OUTPUT_CHANNELS, KERNEL_SIZE) for each convolutional layer\n",
    "            L => a list containing a tuple (INPUT_CHANNELS, OUTPUT_CHANNELS) for each linear layer\n",
    "        \n",
    "        `data` can be passed to indicate which default network to use.\n",
    "        \n",
    "        `random_rotate` can be used to make the network generalize better.\n",
    "        However, there are some data requirements for it to work, which is why it is disabled by default.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create zero padding\n",
    "        self.padVer = lambda x: F.pad(x, (0, 0, 1, 1), mode='constant')\n",
    "        self.padHor = lambda x: F.pad(x, (1, 1, 0, 0), mode='constant')\n",
    "        \n",
    "        # Define the pooling used\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Create lists used for the convolutional- and linear layers.\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.fcs = nn.ModuleList()\n",
    "        self.view = -1\n",
    "        \n",
    "        self.random_rotate = random_rotate\n",
    "        \n",
    "        if layers is None:\n",
    "            # If no layers are passed, create the default network\n",
    "            # The default network is dependent on the data set\n",
    "            if data == 'MNIST':\n",
    "                # Default network for MNIST dataset\n",
    "                self.convs.append(nn.Conv2d(1, 3, 3))\n",
    "                self.convs.append(nn.Conv2d(3, 8, 3))\n",
    "                self.convs.append(nn.Conv2d(8, 16, 3))\n",
    "                self.convs.append(nn.Conv2d(16, 32, 3))\n",
    "                self.convs.append(nn.Conv2d(32, 64, 3))\n",
    "\n",
    "                self.view = 64\n",
    "\n",
    "                self.fcs.append(nn.Linear(64, 32))\n",
    "                self.fcs.append(nn.Linear(32, 24))\n",
    "                self.fcs.append(nn.Linear(24, 10))\n",
    "\n",
    "            if data == 'CAP':\n",
    "                # Default network for CAP dataset\n",
    "                self.convs.append(nn.Conv2d(3, 4, 3))\n",
    "                self.convs.append(nn.Conv2d(4, 6, 3))\n",
    "                self.convs.append(nn.Conv2d(6, 12, 3))\n",
    "                self.convs.append(nn.Conv2d(12, 16, 3))\n",
    "                self.convs.append(nn.Conv2d(16, 24, 3))\n",
    "\n",
    "                self.view = 24\n",
    "\n",
    "                self.fcs.append(nn.Linear(24, 12))\n",
    "                self.fcs.append(nn.Linear(12, NUM_CLASSES_CAP))\n",
    "        else:\n",
    "            # Parse the given layers\n",
    "            for cl in layers[0]:\n",
    "                self.convs.append(nn.Conv2d(cl[0], cl[1], cl[2]))\n",
    "            for fcl in layers[1]:\n",
    "                self.fcs.append(nn.Linear(fcl[0], fcl[1]))\n",
    "            self.view = layers[1][0][0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.random_rotate:\n",
    "            # Randomly rotate the input data is the option is enabled.\n",
    "            x = random_rotate(x)\n",
    "        # Run the sample through all convolutional layers\n",
    "        for conv in self.convs:\n",
    "            x = self.pool(F.relu(conv(self.padVer(self.padHor(x)))))\n",
    "        # Run the result from the convolution through the linear layers\n",
    "        x = x.view(-1, self.view)\n",
    "        for l in self.fcs[:-1]:\n",
    "            x = F.relu(l(x))\n",
    "        # Don't use the relu for the last layer\n",
    "        x = self.fcs[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and testing\n",
    "\n",
    "The train function trains a given network and provides intermediate updates in the form of console logs.\n",
    "The test function test the accuracy on the test images and the randomly rotated test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data, epochs, lrs=[(0, 0.001), (1, 0.0001)], momentum=0.9, print_interval=2000, train_proportion=0.8):\n",
    "    set_seed()\n",
    "    \n",
    "    train_loader, _ = load_data(data, train_proportion)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=momentum)\n",
    "    \n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = \"cpu\"\n",
    "    net.to(device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Started at: \" + time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    \n",
    "    for epoch in range(epochs):  \n",
    "        print('== Starting epoch ' + str(epoch) + ' ==')\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for e, lr in lrs:\n",
    "            if epoch == e:\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = lr\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % print_interval == print_interval - 1:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / print_interval))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Finished Training in: ' + str(timedelta(seconds=elapsed_time)))\n",
    "\n",
    "def test(net, data, test_proportion=0.2):\n",
    "    set_seed()\n",
    "    \n",
    "    _, test_loader = load_data(data, test_proportion)\n",
    "    device = \"cpu\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the', len(test_loader), 'test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(random_rotate(images))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the', len(test_loader), 'randomly rotated test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expiriment MNIST dataset\n",
    "\n",
    "We first define the 4 mentioned models and the train them. This is followed by testing each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 09:56:04\n",
      "== Starting epoch 0 ==\n",
      "[1,  2000] loss: 2.304\n",
      "[1,  4000] loss: 2.305\n",
      "[1,  6000] loss: 2.302\n",
      "[1,  8000] loss: 2.305\n",
      "[1, 10000] loss: 2.303\n",
      "[1, 12000] loss: 2.305\n",
      "[1, 14000] loss: 2.304\n",
      "[1, 16000] loss: 2.304\n",
      "[1, 18000] loss: 2.301\n",
      "[1, 20000] loss: 2.305\n",
      "[1, 22000] loss: 2.303\n",
      "[1, 24000] loss: 2.304\n",
      "[1, 26000] loss: 2.299\n",
      "[1, 28000] loss: 2.158\n",
      "[1, 30000] loss: 1.711\n",
      "[1, 32000] loss: 1.497\n",
      "[1, 34000] loss: 1.315\n",
      "[1, 36000] loss: 1.292\n",
      "[1, 38000] loss: 1.032\n",
      "[1, 40000] loss: 0.931\n",
      "[1, 42000] loss: 0.904\n",
      "[1, 44000] loss: 0.759\n",
      "[1, 46000] loss: 0.685\n",
      "[1, 48000] loss: 0.740\n",
      "[1, 50000] loss: 0.708\n",
      "[1, 52000] loss: 0.589\n",
      "[1, 54000] loss: 0.631\n",
      "[1, 56000] loss: 0.523\n",
      "[1, 58000] loss: 0.493\n",
      "[1, 60000] loss: 0.446\n",
      "== Starting epoch 1 ==\n",
      "[2,  2000] loss: 0.438\n",
      "[2,  4000] loss: 0.355\n",
      "[2,  6000] loss: 0.415\n",
      "[2,  8000] loss: 0.405\n",
      "[2, 10000] loss: 0.401\n",
      "[2, 12000] loss: 0.342\n",
      "[2, 14000] loss: 0.327\n",
      "[2, 16000] loss: 0.407\n",
      "[2, 18000] loss: 0.345\n",
      "[2, 20000] loss: 0.336\n",
      "[2, 22000] loss: 0.270\n",
      "[2, 24000] loss: 0.305\n",
      "[2, 26000] loss: 0.320\n",
      "[2, 28000] loss: 0.296\n",
      "[2, 30000] loss: 0.336\n",
      "[2, 32000] loss: 0.382\n",
      "[2, 34000] loss: 0.277\n",
      "[2, 36000] loss: 0.319\n",
      "[2, 38000] loss: 0.275\n",
      "[2, 40000] loss: 0.336\n",
      "[2, 42000] loss: 0.296\n",
      "[2, 44000] loss: 0.301\n",
      "[2, 46000] loss: 0.282\n",
      "[2, 48000] loss: 0.361\n",
      "[2, 50000] loss: 0.326\n",
      "[2, 52000] loss: 0.279\n",
      "[2, 54000] loss: 0.319\n",
      "[2, 56000] loss: 0.222\n",
      "[2, 58000] loss: 0.260\n",
      "[2, 60000] loss: 0.197\n",
      "Finished Training\n",
      "Finished Training in: 0:07:55.723842\n",
      "Started at: 10:04:00\n",
      "== Starting epoch 0 ==\n",
      "[1,  2000] loss: 2.306\n",
      "[1,  4000] loss: 2.305\n",
      "[1,  6000] loss: 2.302\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.301\n",
      "[1, 12000] loss: 2.293\n",
      "[1, 14000] loss: 2.049\n",
      "[1, 16000] loss: 1.742\n",
      "[1, 18000] loss: 1.410\n",
      "[1, 20000] loss: 1.148\n",
      "[1, 22000] loss: 0.937\n",
      "[1, 24000] loss: 0.894\n",
      "[1, 26000] loss: 0.712\n",
      "[1, 28000] loss: 0.586\n",
      "[1, 30000] loss: 0.660\n",
      "[1, 32000] loss: 0.694\n",
      "[1, 34000] loss: 0.529\n",
      "[1, 36000] loss: 0.496\n",
      "[1, 38000] loss: 0.479\n",
      "[1, 40000] loss: 0.527\n",
      "[1, 42000] loss: 0.482\n",
      "[1, 44000] loss: 0.443\n",
      "[1, 46000] loss: 0.423\n",
      "[1, 48000] loss: 0.456\n",
      "[1, 50000] loss: 0.474\n",
      "[1, 52000] loss: 0.388\n",
      "[1, 54000] loss: 0.400\n",
      "[1, 56000] loss: 0.357\n",
      "[1, 58000] loss: 0.387\n",
      "[1, 60000] loss: 0.291\n",
      "== Starting epoch 1 ==\n",
      "[2,  2000] loss: 0.329\n",
      "[2,  4000] loss: 0.249\n",
      "[2,  6000] loss: 0.289\n",
      "[2,  8000] loss: 0.294\n",
      "[2, 10000] loss: 0.287\n",
      "[2, 12000] loss: 0.284\n",
      "[2, 14000] loss: 0.236\n",
      "[2, 16000] loss: 0.264\n",
      "[2, 18000] loss: 0.255\n",
      "[2, 20000] loss: 0.231\n",
      "[2, 22000] loss: 0.212\n",
      "[2, 24000] loss: 0.212\n",
      "[2, 26000] loss: 0.236\n",
      "[2, 28000] loss: 0.224\n",
      "[2, 30000] loss: 0.244\n",
      "[2, 32000] loss: 0.279\n",
      "[2, 34000] loss: 0.191\n",
      "[2, 36000] loss: 0.213\n",
      "[2, 38000] loss: 0.193\n",
      "[2, 40000] loss: 0.215\n",
      "[2, 42000] loss: 0.191\n",
      "[2, 44000] loss: 0.235\n",
      "[2, 46000] loss: 0.196\n",
      "[2, 48000] loss: 0.230\n",
      "[2, 50000] loss: 0.235\n",
      "[2, 52000] loss: 0.174\n",
      "[2, 54000] loss: 0.212\n",
      "[2, 56000] loss: 0.157\n",
      "[2, 58000] loss: 0.174\n",
      "[2, 60000] loss: 0.152\n",
      "Finished Training\n",
      "Finished Training in: 0:07:52.075072\n",
      "Started at: 10:11:52\n",
      "== Starting epoch 0 ==\n",
      "[1,  2000] loss: 2.307\n",
      "[1,  4000] loss: 2.305\n",
      "[1,  6000] loss: 2.302\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.303\n",
      "[1, 12000] loss: 2.305\n",
      "[1, 14000] loss: 2.305\n",
      "[1, 16000] loss: 2.304\n",
      "[1, 18000] loss: 2.301\n",
      "[1, 20000] loss: 2.305\n",
      "[1, 22000] loss: 2.303\n",
      "[1, 24000] loss: 2.304\n",
      "[1, 26000] loss: 2.296\n",
      "[1, 28000] loss: 2.190\n",
      "[1, 30000] loss: 1.957\n",
      "[1, 32000] loss: 1.853\n",
      "[1, 34000] loss: 1.750\n",
      "[1, 36000] loss: 1.698\n",
      "[1, 38000] loss: 1.545\n",
      "[1, 40000] loss: 1.362\n",
      "[1, 42000] loss: 1.311\n",
      "[1, 44000] loss: 1.199\n",
      "[1, 46000] loss: 1.075\n",
      "[1, 48000] loss: 1.065\n",
      "[1, 50000] loss: 1.072\n",
      "[1, 52000] loss: 0.933\n",
      "[1, 54000] loss: 0.896\n",
      "[1, 56000] loss: 0.870\n",
      "[1, 58000] loss: 0.858\n",
      "[1, 60000] loss: 0.751\n",
      "== Starting epoch 1 ==\n",
      "[2,  2000] loss: 0.712\n",
      "[2,  4000] loss: 0.513\n",
      "[2,  6000] loss: 0.559\n",
      "[2,  8000] loss: 0.545\n",
      "[2, 10000] loss: 0.549\n",
      "[2, 12000] loss: 0.493\n",
      "[2, 14000] loss: 0.489\n",
      "[2, 16000] loss: 0.543\n",
      "[2, 18000] loss: 0.492\n",
      "[2, 20000] loss: 0.437\n",
      "[2, 22000] loss: 0.415\n",
      "[2, 24000] loss: 0.405\n",
      "[2, 26000] loss: 0.447\n",
      "[2, 28000] loss: 0.406\n",
      "[2, 30000] loss: 0.468\n",
      "[2, 32000] loss: 0.516\n",
      "[2, 34000] loss: 0.425\n",
      "[2, 36000] loss: 0.448\n",
      "[2, 38000] loss: 0.399\n",
      "[2, 40000] loss: 0.493\n",
      "[2, 42000] loss: 0.434\n",
      "[2, 44000] loss: 0.453\n",
      "[2, 46000] loss: 0.415\n",
      "[2, 48000] loss: 0.494\n",
      "[2, 50000] loss: 0.459\n",
      "[2, 52000] loss: 0.376\n",
      "[2, 54000] loss: 0.414\n",
      "[2, 56000] loss: 0.349\n",
      "[2, 58000] loss: 0.372\n",
      "[2, 60000] loss: 0.300\n",
      "Finished Training\n",
      "Finished Training in: 0:06:06.999287\n",
      "Started at: 10:17:59\n",
      "== Starting epoch 0 ==\n",
      "[1,  2000] loss: 2.307\n",
      "[1,  4000] loss: 2.305\n",
      "[1,  6000] loss: 2.302\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.303\n",
      "[1, 12000] loss: 2.305\n",
      "[1, 14000] loss: 2.303\n",
      "[1, 16000] loss: 2.284\n",
      "[1, 18000] loss: 1.898\n",
      "[1, 20000] loss: 1.402\n",
      "[1, 22000] loss: 0.975\n",
      "[1, 24000] loss: 0.715\n",
      "[1, 26000] loss: 0.525\n",
      "[1, 28000] loss: 0.460\n",
      "[1, 30000] loss: 0.446\n",
      "[1, 32000] loss: 0.395\n",
      "[1, 34000] loss: 0.299\n",
      "[1, 36000] loss: 0.289\n",
      "[1, 38000] loss: 0.283\n",
      "[1, 40000] loss: 0.288\n",
      "[1, 42000] loss: 0.260\n",
      "[1, 44000] loss: 0.231\n",
      "[1, 46000] loss: 0.251\n",
      "[1, 48000] loss: 0.260\n",
      "[1, 50000] loss: 0.220\n",
      "[1, 52000] loss: 0.178\n",
      "[1, 54000] loss: 0.263\n",
      "[1, 56000] loss: 0.195\n",
      "[1, 58000] loss: 0.231\n",
      "[1, 60000] loss: 0.134\n",
      "== Starting epoch 1 ==\n",
      "[2,  2000] loss: 0.167\n",
      "[2,  4000] loss: 0.106\n",
      "[2,  6000] loss: 0.136\n",
      "[2,  8000] loss: 0.140\n",
      "[2, 10000] loss: 0.124\n",
      "[2, 12000] loss: 0.120\n",
      "[2, 14000] loss: 0.128\n",
      "[2, 16000] loss: 0.132\n",
      "[2, 18000] loss: 0.122\n",
      "[2, 20000] loss: 0.083\n",
      "[2, 22000] loss: 0.081\n",
      "[2, 24000] loss: 0.107\n",
      "[2, 26000] loss: 0.100\n",
      "[2, 28000] loss: 0.089\n",
      "[2, 30000] loss: 0.100\n",
      "[2, 32000] loss: 0.103\n",
      "[2, 34000] loss: 0.089\n",
      "[2, 36000] loss: 0.099\n",
      "[2, 38000] loss: 0.096\n",
      "[2, 40000] loss: 0.092\n",
      "[2, 42000] loss: 0.091\n",
      "[2, 44000] loss: 0.086\n",
      "[2, 46000] loss: 0.074\n",
      "[2, 48000] loss: 0.101\n",
      "[2, 50000] loss: 0.080\n",
      "[2, 52000] loss: 0.063\n",
      "[2, 54000] loss: 0.097\n",
      "[2, 56000] loss: 0.055\n",
      "[2, 58000] loss: 0.058\n",
      "[2, 60000] loss: 0.042\n",
      "Finished Training\n",
      "Finished Training in: 0:06:06.207755\n"
     ]
    }
   ],
   "source": [
    "cycnn_R = CyNet(data='MNIST', random_rotate=True)\n",
    "train(cycnn_R, 'MNIST', 2, lrs=[(0, 0.001), (1, 0.0001)])\n",
    "\n",
    "cycnn = CyNet(data='MNIST', random_rotate=False)\n",
    "train(cycnn, 'MNIST', 2, lrs=[(0, 0.001), (1, 0.0001)])\n",
    "\n",
    "cnn_R = CNN(data='MNIST', random_rotate=True)\n",
    "train(cnn_R, 'MNIST', 2, lrs=[(0, 0.001), (1, 0.0001)])\n",
    "\n",
    "cnn = CNN(data='MNIST', random_rotate=False)\n",
    "train(cnn, 'MNIST', 2, lrs=[(0, 0.001), (1, 0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CyCNN Rotated Training ==\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "Accuracy of the network on the 10000 randomly rotated test images: 91 %\n",
      "== CyCNN Normal Training ==\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 randomly rotated test images: 71 %\n",
      "== CNN Rotated Training ==\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 randomly rotated test images: 87 %\n",
      "== CNN Normal Training ==\n",
      "Accuracy of the network on the 10000 test images: 97 %\n",
      "Accuracy of the network on the 10000 randomly rotated test images: 42 %\n"
     ]
    }
   ],
   "source": [
    "print('== CyCNN Rotated Training ==')\n",
    "test(cycnn_R, 'MNIST')\n",
    "\n",
    "print('== CyCNN Normal Training ==')\n",
    "test(cycnn, 'MNIST')\n",
    "\n",
    "print('== CNN Rotated Training ==')\n",
    "test(cnn_R, 'MNIST')\n",
    "\n",
    "print('== CNN Normal Training ==')\n",
    "test(cnn, 'MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expiriment beer cap dataset\n",
    "\n",
    "We first define the 4 mentioned models and the train them. This is followed by testing each model.\n",
    "Then we train the models on varying amounts training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 17:11:41\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.349\n",
      "[1,  1500] loss: 1.145\n",
      "[1,  2000] loss: 0.858\n",
      "[1,  2500] loss: 0.691\n",
      "[1,  3000] loss: 0.494\n",
      "[1,  3500] loss: 0.474\n",
      "[1,  4000] loss: 0.395\n",
      "[1,  4500] loss: 0.326\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.347\n",
      "[2,  1000] loss: 0.319\n",
      "[2,  1500] loss: 0.308\n",
      "[2,  2000] loss: 0.289\n",
      "[2,  2500] loss: 0.245\n",
      "[2,  3000] loss: 0.274\n",
      "[2,  3500] loss: 0.316\n",
      "[2,  4000] loss: 0.319\n",
      "[2,  4500] loss: 0.273\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.266\n",
      "[3,  1000] loss: 0.154\n",
      "[3,  1500] loss: 0.327\n",
      "[3,  2000] loss: 0.168\n",
      "[3,  2500] loss: 0.149\n",
      "[3,  3000] loss: 0.160\n",
      "[3,  3500] loss: 0.163\n",
      "[3,  4000] loss: 0.139\n",
      "[3,  4500] loss: 0.165\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.119\n",
      "[4,  1000] loss: 0.172\n",
      "[4,  1500] loss: 0.121\n",
      "[4,  2000] loss: 0.109\n",
      "[4,  2500] loss: 0.129\n",
      "[4,  3000] loss: 0.103\n",
      "[4,  3500] loss: 0.093\n",
      "[4,  4000] loss: 0.122\n",
      "[4,  4500] loss: 0.087\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.155\n",
      "[5,  1000] loss: 0.091\n",
      "[5,  1500] loss: 0.118\n",
      "[5,  2000] loss: 0.087\n",
      "[5,  2500] loss: 0.086\n",
      "[5,  3000] loss: 0.127\n",
      "[5,  3500] loss: 0.144\n",
      "[5,  4000] loss: 0.065\n",
      "[5,  4500] loss: 0.037\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.043\n",
      "[6,  1000] loss: 0.043\n",
      "[6,  1500] loss: 0.074\n",
      "[6,  2000] loss: 0.051\n",
      "[6,  2500] loss: 0.043\n",
      "[6,  3000] loss: 0.032\n",
      "[6,  3500] loss: 0.034\n",
      "[6,  4000] loss: 0.042\n",
      "[6,  4500] loss: 0.032\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.037\n",
      "[7,  1000] loss: 0.041\n",
      "[7,  1500] loss: 0.035\n",
      "[7,  2000] loss: 0.021\n",
      "[7,  2500] loss: 0.050\n",
      "[7,  3000] loss: 0.025\n",
      "[7,  3500] loss: 0.020\n",
      "[7,  4000] loss: 0.033\n",
      "[7,  4500] loss: 0.025\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.025\n",
      "[8,  1000] loss: 0.037\n",
      "[8,  1500] loss: 0.024\n",
      "[8,  2000] loss: 0.023\n",
      "[8,  2500] loss: 0.030\n",
      "[8,  3000] loss: 0.044\n",
      "[8,  3500] loss: 0.025\n",
      "[8,  4000] loss: 0.041\n",
      "[8,  4500] loss: 0.031\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.024\n",
      "[9,  1000] loss: 0.030\n",
      "[9,  1500] loss: 0.022\n",
      "[9,  2000] loss: 0.039\n",
      "[9,  2500] loss: 0.034\n",
      "[9,  3000] loss: 0.028\n",
      "[9,  3500] loss: 0.024\n",
      "[9,  4000] loss: 0.018\n",
      "[9,  4500] loss: 0.021\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.017\n",
      "[10,  1000] loss: 0.010\n",
      "[10,  1500] loss: 0.028\n",
      "[10,  2000] loss: 0.019\n",
      "[10,  2500] loss: 0.020\n",
      "[10,  3000] loss: 0.020\n",
      "[10,  3500] loss: 0.027\n",
      "[10,  4000] loss: 0.028\n",
      "[10,  4500] loss: 0.025\n",
      "Finished Training\n",
      "Finished Training in: 0:02:56.900048\n",
      "Started at: 17:14:41\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.391\n",
      "[1,  1000] loss: 1.366\n",
      "[1,  1500] loss: 1.209\n",
      "[1,  2000] loss: 0.922\n",
      "[1,  2500] loss: 0.712\n",
      "[1,  3000] loss: 0.998\n",
      "[1,  3500] loss: 0.716\n",
      "[1,  4000] loss: 0.561\n",
      "[1,  4500] loss: 0.445\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.387\n",
      "[2,  1000] loss: 0.384\n",
      "[2,  1500] loss: 0.316\n",
      "[2,  2000] loss: 0.305\n",
      "[2,  2500] loss: 0.299\n",
      "[2,  3000] loss: 0.258\n",
      "[2,  3500] loss: 0.240\n",
      "[2,  4000] loss: 0.366\n",
      "[2,  4500] loss: 0.312\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.310\n",
      "[3,  1000] loss: 0.200\n",
      "[3,  1500] loss: 0.211\n",
      "[3,  2000] loss: 0.321\n",
      "[3,  2500] loss: 0.185\n",
      "[3,  3000] loss: 0.183\n",
      "[3,  3500] loss: 0.179\n",
      "[3,  4000] loss: 0.148\n",
      "[3,  4500] loss: 0.152\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.169\n",
      "[4,  1000] loss: 0.128\n",
      "[4,  1500] loss: 0.111\n",
      "[4,  2000] loss: 0.234\n",
      "[4,  2500] loss: 0.182\n",
      "[4,  3000] loss: 0.157\n",
      "[4,  3500] loss: 0.184\n",
      "[4,  4000] loss: 0.170\n",
      "[4,  4500] loss: 0.100\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.230\n",
      "[5,  1000] loss: 0.118\n",
      "[5,  1500] loss: 0.177\n",
      "[5,  2000] loss: 0.125\n",
      "[5,  2500] loss: 0.086\n",
      "[5,  3000] loss: 0.131\n",
      "[5,  3500] loss: 0.136\n",
      "[5,  4000] loss: 0.197\n",
      "[5,  4500] loss: 0.095\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.054\n",
      "[6,  1000] loss: 0.053\n",
      "[6,  1500] loss: 0.039\n",
      "[6,  2000] loss: 0.034\n",
      "[6,  2500] loss: 0.039\n",
      "[6,  3000] loss: 0.033\n",
      "[6,  3500] loss: 0.018\n",
      "[6,  4000] loss: 0.037\n",
      "[6,  4500] loss: 0.016\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.015\n",
      "[7,  1000] loss: 0.014\n",
      "[7,  1500] loss: 0.015\n",
      "[7,  2000] loss: 0.012\n",
      "[7,  2500] loss: 0.029\n",
      "[7,  3000] loss: 0.038\n",
      "[7,  3500] loss: 0.017\n",
      "[7,  4000] loss: 0.013\n",
      "[7,  4500] loss: 0.004\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.022\n",
      "[8,  1000] loss: 0.019\n",
      "[8,  1500] loss: 0.006\n",
      "[8,  2000] loss: 0.005\n",
      "[8,  2500] loss: 0.007\n",
      "[8,  3000] loss: 0.013\n",
      "[8,  3500] loss: 0.009\n",
      "[8,  4000] loss: 0.012\n",
      "[8,  4500] loss: 0.014\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.015\n",
      "[9,  1000] loss: 0.005\n",
      "[9,  1500] loss: 0.008\n",
      "[9,  2000] loss: 0.026\n",
      "[9,  2500] loss: 0.006\n",
      "[9,  3000] loss: 0.013\n",
      "[9,  3500] loss: 0.006\n",
      "[9,  4000] loss: 0.003\n",
      "[9,  4500] loss: 0.004\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.011\n",
      "[10,  1000] loss: 0.006\n",
      "[10,  1500] loss: 0.004\n",
      "[10,  2000] loss: 0.004\n",
      "[10,  2500] loss: 0.004\n",
      "[10,  3000] loss: 0.006\n",
      "[10,  3500] loss: 0.004\n",
      "[10,  4000] loss: 0.007\n",
      "[10,  4500] loss: 0.002\n",
      "Finished Training\n",
      "Finished Training in: 0:03:00.120935\n",
      "Started at: 17:17:45\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.393\n",
      "[1,  1000] loss: 1.389\n",
      "[1,  1500] loss: 1.376\n",
      "[1,  2000] loss: 1.261\n",
      "[1,  2500] loss: 1.003\n",
      "[1,  3000] loss: 0.916\n",
      "[1,  3500] loss: 0.869\n",
      "[1,  4000] loss: 0.760\n",
      "[1,  4500] loss: 0.651\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.512\n",
      "[2,  1000] loss: 0.473\n",
      "[2,  1500] loss: 0.413\n",
      "[2,  2000] loss: 0.412\n",
      "[2,  2500] loss: 0.385\n",
      "[2,  3000] loss: 0.337\n",
      "[2,  3500] loss: 0.298\n",
      "[2,  4000] loss: 0.423\n",
      "[2,  4500] loss: 0.317\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.335\n",
      "[3,  1000] loss: 0.288\n",
      "[3,  1500] loss: 0.326\n",
      "[3,  2000] loss: 0.292\n",
      "[3,  2500] loss: 0.281\n",
      "[3,  3000] loss: 0.300\n",
      "[3,  3500] loss: 0.331\n",
      "[3,  4000] loss: 0.264\n",
      "[3,  4500] loss: 0.258\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.227\n",
      "[4,  1000] loss: 0.219\n",
      "[4,  1500] loss: 0.234\n",
      "[4,  2000] loss: 0.275\n",
      "[4,  2500] loss: 0.219\n",
      "[4,  3000] loss: 0.216\n",
      "[4,  3500] loss: 0.193\n",
      "[4,  4000] loss: 0.257\n",
      "[4,  4500] loss: 0.261\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.268\n",
      "[5,  1000] loss: 0.227\n",
      "[5,  1500] loss: 0.237\n",
      "[5,  2000] loss: 0.218\n",
      "[5,  2500] loss: 0.208\n",
      "[5,  3000] loss: 0.250\n",
      "[5,  3500] loss: 0.219\n",
      "[5,  4000] loss: 0.202\n",
      "[5,  4500] loss: 0.214\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.155\n",
      "[6,  1000] loss: 0.189\n",
      "[6,  1500] loss: 0.196\n",
      "[6,  2000] loss: 0.144\n",
      "[6,  2500] loss: 0.154\n",
      "[6,  3000] loss: 0.146\n",
      "[6,  3500] loss: 0.163\n",
      "[6,  4000] loss: 0.157\n",
      "[6,  4500] loss: 0.133\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.145\n",
      "[7,  1000] loss: 0.137\n",
      "[7,  1500] loss: 0.124\n",
      "[7,  2000] loss: 0.119\n",
      "[7,  2500] loss: 0.143\n",
      "[7,  3000] loss: 0.132\n",
      "[7,  3500] loss: 0.143\n",
      "[7,  4000] loss: 0.134\n",
      "[7,  4500] loss: 0.119\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.141\n",
      "[8,  1000] loss: 0.145\n",
      "[8,  1500] loss: 0.135\n",
      "[8,  2000] loss: 0.158\n",
      "[8,  2500] loss: 0.123\n",
      "[8,  3000] loss: 0.132\n",
      "[8,  3500] loss: 0.118\n",
      "[8,  4000] loss: 0.141\n",
      "[8,  4500] loss: 0.131\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.143\n",
      "[9,  1000] loss: 0.107\n",
      "[9,  1500] loss: 0.100\n",
      "[9,  2000] loss: 0.154\n",
      "[9,  2500] loss: 0.141\n",
      "[9,  3000] loss: 0.121\n",
      "[9,  3500] loss: 0.148\n",
      "[9,  4000] loss: 0.114\n",
      "[9,  4500] loss: 0.101\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.130\n",
      "[10,  1000] loss: 0.116\n",
      "[10,  1500] loss: 0.123\n",
      "[10,  2000] loss: 0.099\n",
      "[10,  2500] loss: 0.117\n",
      "[10,  3000] loss: 0.134\n",
      "[10,  3500] loss: 0.104\n",
      "[10,  4000] loss: 0.105\n",
      "[10,  4500] loss: 0.123\n",
      "Finished Training\n",
      "Finished Training in: 0:02:24.082292\n",
      "Started at: 17:20:12\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.393\n",
      "[1,  1000] loss: 1.388\n",
      "[1,  1500] loss: 1.374\n",
      "[1,  2000] loss: 1.231\n",
      "[1,  2500] loss: 0.904\n",
      "[1,  3000] loss: 0.702\n",
      "[1,  3500] loss: 0.544\n",
      "[1,  4000] loss: 0.538\n",
      "[1,  4500] loss: 0.401\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.444\n",
      "[2,  1000] loss: 0.405\n",
      "[2,  1500] loss: 0.402\n",
      "[2,  2000] loss: 0.360\n",
      "[2,  2500] loss: 0.327\n",
      "[2,  3000] loss: 0.309\n",
      "[2,  3500] loss: 0.291\n",
      "[2,  4000] loss: 0.335\n",
      "[2,  4500] loss: 0.264\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.394\n",
      "[3,  1000] loss: 0.337\n",
      "[3,  1500] loss: 0.297\n",
      "[3,  2000] loss: 0.255\n",
      "[3,  2500] loss: 0.217\n",
      "[3,  3000] loss: 0.245\n",
      "[3,  3500] loss: 0.250\n",
      "[3,  4000] loss: 0.222\n",
      "[3,  4500] loss: 0.216\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.217\n",
      "[4,  1000] loss: 0.199\n",
      "[4,  1500] loss: 0.154\n",
      "[4,  2000] loss: 0.191\n",
      "[4,  2500] loss: 0.207\n",
      "[4,  3000] loss: 0.199\n",
      "[4,  3500] loss: 0.165\n",
      "[4,  4000] loss: 0.264\n",
      "[4,  4500] loss: 0.380\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.279\n",
      "[5,  1000] loss: 0.259\n",
      "[5,  1500] loss: 0.312\n",
      "[5,  2000] loss: 0.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  2500] loss: 0.213\n",
      "[5,  3000] loss: 0.223\n",
      "[5,  3500] loss: 0.197\n",
      "[5,  4000] loss: 0.179\n",
      "[5,  4500] loss: 0.149\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.109\n",
      "[6,  1000] loss: 0.155\n",
      "[6,  1500] loss: 0.152\n",
      "[6,  2000] loss: 0.104\n",
      "[6,  2500] loss: 0.126\n",
      "[6,  3000] loss: 0.111\n",
      "[6,  3500] loss: 0.109\n",
      "[6,  4000] loss: 0.127\n",
      "[6,  4500] loss: 0.113\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.106\n",
      "[7,  1000] loss: 0.087\n",
      "[7,  1500] loss: 0.085\n",
      "[7,  2000] loss: 0.084\n",
      "[7,  2500] loss: 0.091\n",
      "[7,  3000] loss: 0.063\n",
      "[7,  3500] loss: 0.080\n",
      "[7,  4000] loss: 0.098\n",
      "[7,  4500] loss: 0.081\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.078\n",
      "[8,  1000] loss: 0.088\n",
      "[8,  1500] loss: 0.060\n",
      "[8,  2000] loss: 0.078\n",
      "[8,  2500] loss: 0.057\n",
      "[8,  3000] loss: 0.080\n",
      "[8,  3500] loss: 0.063\n",
      "[8,  4000] loss: 0.104\n",
      "[8,  4500] loss: 0.088\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.086\n",
      "[9,  1000] loss: 0.056\n",
      "[9,  1500] loss: 0.040\n",
      "[9,  2000] loss: 0.084\n",
      "[9,  2500] loss: 0.093\n",
      "[9,  3000] loss: 0.059\n",
      "[9,  3500] loss: 0.061\n",
      "[9,  4000] loss: 0.054\n",
      "[9,  4500] loss: 0.063\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.067\n",
      "[10,  1000] loss: 0.069\n",
      "[10,  1500] loss: 0.059\n",
      "[10,  2000] loss: 0.055\n",
      "[10,  2500] loss: 0.060\n",
      "[10,  3000] loss: 0.060\n",
      "[10,  3500] loss: 0.058\n",
      "[10,  4000] loss: 0.055\n",
      "[10,  4500] loss: 0.060\n",
      "Finished Training\n",
      "Finished Training in: 0:02:13.366734\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# TEST CNN AND CYCNN ON FULL BEER CAP DATASET\n",
    "# -------------------------------------------\n",
    "\n",
    "cycnn_R = CyNet(data='CAP', random_rotate=True)\n",
    "train(cycnn_R, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500)\n",
    "\n",
    "cycnn = CyNet(data='CAP', random_rotate=False)\n",
    "train(cycnn, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500)\n",
    "\n",
    "cnn_R = CNN(data='CAP', random_rotate=True)\n",
    "train(cnn_R, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500)\n",
    "\n",
    "cnn = CNN(data='CAP', random_rotate=False)\n",
    "train(cnn, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CyCNN Rotated Training ==\n",
      "Accuracy of the network on the 1154 test images: 98 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 99 %\n",
      "== CyCNN Normal Training ==\n",
      "Accuracy of the network on the 1154 test images: 99 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 99 %\n",
      "== CNN Rotated Training ==\n",
      "Accuracy of the network on the 1154 test images: 96 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 97 %\n",
      "== CNN Normal Training ==\n",
      "Accuracy of the network on the 1154 test images: 97 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "print('== CyCNN Rotated Training ==')\n",
    "test(cycnn_R, 'CAP')\n",
    "\n",
    "print('== CyCNN Normal Training ==')\n",
    "test(cycnn, 'CAP')\n",
    "\n",
    "print('== CNN Rotated Training ==')\n",
    "test(cnn_R, 'CAP')\n",
    "\n",
    "print('== CNN Normal Training ==')\n",
    "test(cnn, 'CAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 17:52:55\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.390\n",
      "[1,  1500] loss: 1.385\n",
      "[1,  2000] loss: 1.298\n",
      "[1,  2500] loss: 0.818\n",
      "[1,  3000] loss: 0.516\n",
      "[1,  3500] loss: 0.471\n",
      "[1,  4000] loss: 0.412\n",
      "[1,  4500] loss: 0.280\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.362\n",
      "[2,  1000] loss: 0.321\n",
      "[2,  1500] loss: 0.320\n",
      "[2,  2000] loss: 0.214\n",
      "[2,  2500] loss: 0.252\n",
      "[2,  3000] loss: 0.248\n",
      "[2,  3500] loss: 0.180\n",
      "[2,  4000] loss: 0.200\n",
      "[2,  4500] loss: 0.219\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.339\n",
      "[3,  1000] loss: 0.097\n",
      "[3,  1500] loss: 0.176\n",
      "[3,  2000] loss: 0.119\n",
      "[3,  2500] loss: 0.114\n",
      "[3,  3000] loss: 0.160\n",
      "[3,  3500] loss: 0.216\n",
      "[3,  4000] loss: 0.132\n",
      "[3,  4500] loss: 0.132\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.104\n",
      "[4,  1000] loss: 0.099\n",
      "[4,  1500] loss: 0.089\n",
      "[4,  2000] loss: 0.118\n",
      "[4,  2500] loss: 0.087\n",
      "[4,  3000] loss: 0.117\n",
      "[4,  3500] loss: 0.077\n",
      "[4,  4000] loss: 0.118\n",
      "[4,  4500] loss: 0.058\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.165\n",
      "[5,  1000] loss: 0.192\n",
      "[5,  1500] loss: 0.152\n",
      "[5,  2000] loss: 0.177\n",
      "[5,  2500] loss: 0.135\n",
      "[5,  3000] loss: 0.113\n",
      "[5,  3500] loss: 0.163\n",
      "[5,  4000] loss: 0.096\n",
      "[5,  4500] loss: 0.068\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.072\n",
      "[6,  1000] loss: 0.057\n",
      "[6,  1500] loss: 0.070\n",
      "[6,  2000] loss: 0.049\n",
      "[6,  2500] loss: 0.042\n",
      "[6,  3000] loss: 0.049\n",
      "[6,  3500] loss: 0.033\n",
      "[6,  4000] loss: 0.032\n",
      "[6,  4500] loss: 0.065\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.037\n",
      "[7,  1000] loss: 0.050\n",
      "[7,  1500] loss: 0.038\n",
      "[7,  2000] loss: 0.048\n",
      "[7,  2500] loss: 0.059\n",
      "[7,  3000] loss: 0.047\n",
      "[7,  3500] loss: 0.028\n",
      "[7,  4000] loss: 0.043\n",
      "[7,  4500] loss: 0.043\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.043\n",
      "[8,  1000] loss: 0.037\n",
      "[8,  1500] loss: 0.036\n",
      "[8,  2000] loss: 0.058\n",
      "[8,  2500] loss: 0.026\n",
      "[8,  3000] loss: 0.057\n",
      "[8,  3500] loss: 0.046\n",
      "[8,  4000] loss: 0.040\n",
      "[8,  4500] loss: 0.062\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.046\n",
      "[9,  1000] loss: 0.029\n",
      "[9,  1500] loss: 0.034\n",
      "[9,  2000] loss: 0.051\n",
      "[9,  2500] loss: 0.041\n",
      "[9,  3000] loss: 0.029\n",
      "[9,  3500] loss: 0.034\n",
      "[9,  4000] loss: 0.027\n",
      "[9,  4500] loss: 0.025\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.040\n",
      "[10,  1000] loss: 0.039\n",
      "[10,  1500] loss: 0.032\n",
      "[10,  2000] loss: 0.025\n",
      "[10,  2500] loss: 0.031\n",
      "[10,  3000] loss: 0.025\n",
      "[10,  3500] loss: 0.027\n",
      "[10,  4000] loss: 0.036\n",
      "[10,  4500] loss: 0.032\n",
      "Finished Training\n",
      "Finished Training in: 0:02:49.672867\n",
      "Accuracy of the network on the 1154 test images: 98 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 99 %\n",
      "Started at: 17:55:53\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.391\n",
      "[1,  1500] loss: 1.390\n",
      "[1,  2000] loss: 1.386\n",
      "[1,  2500] loss: 1.384\n",
      "[1,  3000] loss: 1.124\n",
      "[1,  3500] loss: 0.790\n",
      "[1,  4000] loss: 0.651\n",
      "[1,  4500] loss: 0.583\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.458\n",
      "[2,  1000] loss: 0.464\n",
      "[2,  1500] loss: 0.382\n",
      "[2,  2000] loss: 0.368\n",
      "[2,  2500] loss: 0.345\n",
      "[2,  3000] loss: 0.320\n",
      "[2,  3500] loss: 0.303\n",
      "[2,  4000] loss: 0.356\n",
      "[2,  4500] loss: 0.337\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.350\n",
      "[3,  1000] loss: 0.280\n",
      "[3,  1500] loss: 0.391\n",
      "[3,  2000] loss: 0.540\n",
      "[3,  2500] loss: 0.296\n",
      "[3,  3000] loss: 0.309\n",
      "[3,  3500] loss: 0.446\n",
      "[3,  4000] loss: 0.255\n",
      "[3,  4500] loss: 0.306\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.218\n",
      "[4,  1000] loss: 0.218\n",
      "[4,  1500] loss: 0.212\n",
      "[4,  2000] loss: 0.278\n",
      "[4,  2500] loss: 0.194\n",
      "[4,  3000] loss: 0.215\n",
      "[4,  3500] loss: 0.487\n",
      "[4,  4000] loss: 0.256\n",
      "[4,  4500] loss: 0.248\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.264\n",
      "[5,  1000] loss: 0.191\n",
      "[5,  1500] loss: 0.223\n",
      "[5,  2000] loss: 0.238\n",
      "[5,  2500] loss: 0.237\n",
      "[5,  3000] loss: 0.265\n",
      "[5,  3500] loss: 0.249\n",
      "[5,  4000] loss: 0.216\n",
      "[5,  4500] loss: 0.241\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.163\n",
      "[6,  1000] loss: 0.198\n",
      "[6,  1500] loss: 0.210\n",
      "[6,  2000] loss: 0.164\n",
      "[6,  2500] loss: 0.159\n",
      "[6,  3000] loss: 0.156\n",
      "[6,  3500] loss: 0.138\n",
      "[6,  4000] loss: 0.167\n",
      "[6,  4500] loss: 0.146\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.172\n",
      "[7,  1000] loss: 0.156\n",
      "[7,  1500] loss: 0.154\n",
      "[7,  2000] loss: 0.134\n",
      "[7,  2500] loss: 0.189\n",
      "[7,  3000] loss: 0.150\n",
      "[7,  3500] loss: 0.146\n",
      "[7,  4000] loss: 0.146\n",
      "[7,  4500] loss: 0.129\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.166\n",
      "[8,  1000] loss: 0.154\n",
      "[8,  1500] loss: 0.149\n",
      "[8,  2000] loss: 0.161\n",
      "[8,  2500] loss: 0.126\n",
      "[8,  3000] loss: 0.155\n",
      "[8,  3500] loss: 0.134\n",
      "[8,  4000] loss: 0.159\n",
      "[8,  4500] loss: 0.151\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.145\n",
      "[9,  1000] loss: 0.132\n",
      "[9,  1500] loss: 0.123\n",
      "[9,  2000] loss: 0.183\n",
      "[9,  2500] loss: 0.151\n",
      "[9,  3000] loss: 0.143\n",
      "[9,  3500] loss: 0.139\n",
      "[9,  4000] loss: 0.127\n",
      "[9,  4500] loss: 0.136\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.149\n",
      "[10,  1000] loss: 0.160\n",
      "[10,  1500] loss: 0.128\n",
      "[10,  2000] loss: 0.111\n",
      "[10,  2500] loss: 0.128\n",
      "[10,  3000] loss: 0.143\n",
      "[10,  3500] loss: 0.124\n",
      "[10,  4000] loss: 0.123\n",
      "[10,  4500] loss: 0.110\n",
      "Finished Training\n",
      "Finished Training in: 0:02:07.444010\n",
      "Accuracy of the network on the 1154 test images: 96 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 96 %\n",
      "Started at: 17:58:07\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.389\n",
      "[1,  1000] loss: 1.386\n",
      "[1,  1500] loss: 1.386\n",
      "[1,  2000] loss: 1.360\n",
      "[1,  2500] loss: 0.949\n",
      "[1,  3000] loss: 0.545\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.369\n",
      "[2,  1000] loss: 0.310\n",
      "[2,  1500] loss: 0.279\n",
      "[2,  2000] loss: 0.279\n",
      "[2,  2500] loss: 0.308\n",
      "[2,  3000] loss: 0.224\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.157\n",
      "[3,  1000] loss: 0.187\n",
      "[3,  1500] loss: 0.183\n",
      "[3,  2000] loss: 0.232\n",
      "[3,  2500] loss: 0.178\n",
      "[3,  3000] loss: 0.192\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.117\n",
      "[4,  1000] loss: 0.320\n",
      "[4,  1500] loss: 0.150\n",
      "[4,  2000] loss: 0.103\n",
      "[4,  2500] loss: 0.141\n",
      "[4,  3000] loss: 0.206\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.120\n",
      "[5,  1000] loss: 0.141\n",
      "[5,  1500] loss: 0.103\n",
      "[5,  2000] loss: 0.124\n",
      "[5,  2500] loss: 0.119\n",
      "[5,  3000] loss: 0.102\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.064\n",
      "[6,  1000] loss: 0.061\n",
      "[6,  1500] loss: 0.052\n",
      "[6,  2000] loss: 0.057\n",
      "[6,  2500] loss: 0.049\n",
      "[6,  3000] loss: 0.075\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.057\n",
      "[7,  1000] loss: 0.045\n",
      "[7,  1500] loss: 0.046\n",
      "[7,  2000] loss: 0.050\n",
      "[7,  2500] loss: 0.027\n",
      "[7,  3000] loss: 0.038\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.033\n",
      "[8,  1000] loss: 0.052\n",
      "[8,  1500] loss: 0.038\n",
      "[8,  2000] loss: 0.034\n",
      "[8,  2500] loss: 0.030\n",
      "[8,  3000] loss: 0.067\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.048\n",
      "[9,  1000] loss: 0.048\n",
      "[9,  1500] loss: 0.025\n",
      "[9,  2000] loss: 0.032\n",
      "[9,  2500] loss: 0.035\n",
      "[9,  3000] loss: 0.023\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.035\n",
      "[10,  1000] loss: 0.040\n",
      "[10,  1500] loss: 0.028\n",
      "[10,  2000] loss: 0.014\n",
      "[10,  2500] loss: 0.025\n",
      "[10,  3000] loss: 0.033\n",
      "Finished Training\n",
      "Finished Training in: 0:02:05.435111\n",
      "Accuracy of the network on the 1154 test images: 99 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 99 %\n",
      "Started at: 18:00:20\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.389\n",
      "[1,  1000] loss: 1.387\n",
      "[1,  1500] loss: 1.388\n",
      "[1,  2000] loss: 1.384\n",
      "[1,  2500] loss: 1.376\n",
      "[1,  3000] loss: 1.093\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.725\n",
      "[2,  1000] loss: 0.516\n",
      "[2,  1500] loss: 0.501\n",
      "[2,  2000] loss: 0.523\n",
      "[2,  2500] loss: 0.364\n",
      "[2,  3000] loss: 0.415\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.340\n",
      "[3,  1000] loss: 0.321\n",
      "[3,  1500] loss: 0.302\n",
      "[3,  2000] loss: 0.363\n",
      "[3,  2500] loss: 0.338\n",
      "[3,  3000] loss: 0.406\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.267\n",
      "[4,  1000] loss: 0.277\n",
      "[4,  1500] loss: 0.262\n",
      "[4,  2000] loss: 0.234\n",
      "[4,  2500] loss: 0.257\n",
      "[4,  3000] loss: 0.463\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.227\n",
      "[5,  1000] loss: 0.250\n",
      "[5,  1500] loss: 0.255\n",
      "[5,  2000] loss: 0.248\n",
      "[5,  2500] loss: 0.243\n",
      "[5,  3000] loss: 0.217\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.169\n",
      "[6,  1000] loss: 0.170\n",
      "[6,  1500] loss: 0.144\n",
      "[6,  2000] loss: 0.153\n",
      "[6,  2500] loss: 0.178\n",
      "[6,  3000] loss: 0.137\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.186\n",
      "[7,  1000] loss: 0.162\n",
      "[7,  1500] loss: 0.142\n",
      "[7,  2000] loss: 0.137\n",
      "[7,  2500] loss: 0.143\n",
      "[7,  3000] loss: 0.159\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.123\n",
      "[8,  1000] loss: 0.169\n",
      "[8,  1500] loss: 0.157\n",
      "[8,  2000] loss: 0.149\n",
      "[8,  2500] loss: 0.145\n",
      "[8,  3000] loss: 0.166\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.145\n",
      "[9,  1000] loss: 0.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  1500] loss: 0.127\n",
      "[9,  2000] loss: 0.125\n",
      "[9,  2500] loss: 0.140\n",
      "[9,  3000] loss: 0.130\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.143\n",
      "[10,  1000] loss: 0.170\n",
      "[10,  1500] loss: 0.124\n",
      "[10,  2000] loss: 0.131\n",
      "[10,  2500] loss: 0.134\n",
      "[10,  3000] loss: 0.174\n",
      "Finished Training\n",
      "Finished Training in: 0:01:36.177486\n",
      "Accuracy of the network on the 1154 test images: 95 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 95 %\n",
      "Started at: 18:02:02\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.387\n",
      "[1,  1500] loss: 1.387\n",
      "[1,  2000] loss: 1.347\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.644\n",
      "[2,  1000] loss: 0.426\n",
      "[2,  1500] loss: 0.374\n",
      "[2,  2000] loss: 0.879\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.386\n",
      "[3,  1000] loss: 0.282\n",
      "[3,  1500] loss: 0.408\n",
      "[3,  2000] loss: 0.261\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.240\n",
      "[4,  1000] loss: 0.218\n",
      "[4,  1500] loss: 0.254\n",
      "[4,  2000] loss: 0.180\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.134\n",
      "[5,  1000] loss: 0.199\n",
      "[5,  1500] loss: 0.118\n",
      "[5,  2000] loss: 0.148\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.110\n",
      "[6,  1000] loss: 0.098\n",
      "[6,  1500] loss: 0.077\n",
      "[6,  2000] loss: 0.106\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.090\n",
      "[7,  1000] loss: 0.076\n",
      "[7,  1500] loss: 0.079\n",
      "[7,  2000] loss: 0.073\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.050\n",
      "[8,  1000] loss: 0.085\n",
      "[8,  1500] loss: 0.052\n",
      "[8,  2000] loss: 0.085\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.075\n",
      "[9,  1000] loss: 0.040\n",
      "[9,  1500] loss: 0.049\n",
      "[9,  2000] loss: 0.038\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.053\n",
      "[10,  1000] loss: 0.067\n",
      "[10,  1500] loss: 0.039\n",
      "[10,  2000] loss: 0.071\n",
      "Finished Training\n",
      "Finished Training in: 0:01:23.356843\n",
      "Accuracy of the network on the 1154 test images: 98 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 98 %\n",
      "Started at: 18:03:32\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.388\n",
      "[1,  1500] loss: 1.389\n",
      "[1,  2000] loss: 1.386\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.163\n",
      "[2,  1000] loss: 0.802\n",
      "[2,  1500] loss: 0.638\n",
      "[2,  2000] loss: 0.479\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.471\n",
      "[3,  1000] loss: 0.370\n",
      "[3,  1500] loss: 0.478\n",
      "[3,  2000] loss: 0.357\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.324\n",
      "[4,  1000] loss: 0.395\n",
      "[4,  1500] loss: 0.469\n",
      "[4,  2000] loss: 0.339\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.304\n",
      "[5,  1000] loss: 0.277\n",
      "[5,  1500] loss: 0.245\n",
      "[5,  2000] loss: 0.280\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.236\n",
      "[6,  1000] loss: 0.212\n",
      "[6,  1500] loss: 0.193\n",
      "[6,  2000] loss: 0.247\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.222\n",
      "[7,  1000] loss: 0.200\n",
      "[7,  1500] loss: 0.182\n",
      "[7,  2000] loss: 0.209\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.176\n",
      "[8,  1000] loss: 0.185\n",
      "[8,  1500] loss: 0.189\n",
      "[8,  2000] loss: 0.192\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.196\n",
      "[9,  1000] loss: 0.162\n",
      "[9,  1500] loss: 0.203\n",
      "[9,  2000] loss: 0.167\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.206\n",
      "[10,  1000] loss: 0.176\n",
      "[10,  1500] loss: 0.185\n",
      "[10,  2000] loss: 0.201\n",
      "Finished Training\n",
      "Finished Training in: 0:01:04.795065\n",
      "Accuracy of the network on the 1154 test images: 94 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 94 %\n",
      "Started at: 18:04:41\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.384\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.382\n",
      "[2,  1000] loss: 1.185\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.605\n",
      "[3,  1000] loss: 0.545\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.387\n",
      "[4,  1000] loss: 0.374\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.305\n",
      "[5,  1000] loss: 0.337\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.199\n",
      "[6,  1000] loss: 0.142\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.149\n",
      "[7,  1000] loss: 0.145\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.157\n",
      "[8,  1000] loss: 0.134\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.144\n",
      "[9,  1000] loss: 0.124\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.096\n",
      "[10,  1000] loss: 0.150\n",
      "Finished Training\n",
      "Finished Training in: 0:00:41.861256\n",
      "Accuracy of the network on the 1154 test images: 93 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 94 %\n",
      "Started at: 18:05:29\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.385\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.388\n",
      "[2,  1000] loss: 1.386\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 1.168\n",
      "[3,  1000] loss: 0.840\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.639\n",
      "[4,  1000] loss: 0.529\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.486\n",
      "[5,  1000] loss: 0.486\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.356\n",
      "[6,  1000] loss: 0.285\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.296\n",
      "[7,  1000] loss: 0.302\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.300\n",
      "[8,  1000] loss: 0.249\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.286\n",
      "[9,  1000] loss: 0.266\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.253\n",
      "[10,  1000] loss: 0.276\n",
      "Finished Training\n",
      "Finished Training in: 0:00:31.479606\n",
      "Accuracy of the network on the 1154 test images: 92 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 92 %\n",
      "Started at: 18:06:05\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.391\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 1.387\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 1.161\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.889\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.778\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.501\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.376\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.377\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.300\n",
      "Finished Training\n",
      "Finished Training in: 0:00:21.218105\n",
      "Accuracy of the network on the 1154 test images: 94 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 94 %\n",
      "Started at: 18:06:31\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.391\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.391\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 1.391\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 1.383\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 1.221\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.953\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.716\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.469\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.418\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.358\n",
      "Finished Training\n",
      "Finished Training in: 0:00:15.783730\n",
      "Accuracy of the network on the 1154 test images: 80 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 82 %\n",
      "Started at: 18:06:52\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:10.364870\n",
      "Accuracy of the network on the 1154 test images: 5 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 5 %\n",
      "Started at: 18:07:07\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:08.156544\n",
      "Accuracy of the network on the 1154 test images: 5 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 5 %\n",
      "Started at: 18:07:19\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:02.064941\n",
      "Accuracy of the network on the 1154 test images: 31 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 31 %\n",
      "Started at: 18:07:26\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:01.583258\n",
      "Accuracy of the network on the 1154 test images: 31 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 31 %\n"
     ]
    }
   ],
   "source": [
    "data_usage = [0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.01]\n",
    "\n",
    "\n",
    "for data_proportion in data_usage:\n",
    "\n",
    "    cycnn = CyNet(data='CAP', random_rotate=True)\n",
    "    train(cycnn, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500, train_proportion=data_proportion)\n",
    "    test(cycnn, 'CAP')\n",
    "    \n",
    "    cnn = CNN(data='CAP', random_rotate=True)\n",
    "    train(cnn, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500, train_proportion=data_proportion)\n",
    "    test(cnn, 'CAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 18:07:35\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.390\n",
      "[1,  1500] loss: 1.384\n",
      "[1,  2000] loss: 1.234\n",
      "[1,  2500] loss: 0.824\n",
      "[1,  3000] loss: 0.646\n",
      "[1,  3500] loss: 0.446\n",
      "[1,  4000] loss: 0.384\n",
      "[1,  4500] loss: 0.308\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.310\n",
      "[2,  1000] loss: 0.343\n",
      "[2,  1500] loss: 0.266\n",
      "[2,  2000] loss: 0.522\n",
      "[2,  2500] loss: 0.197\n",
      "[2,  3000] loss: 0.202\n",
      "[2,  3500] loss: 0.183\n",
      "[2,  4000] loss: 0.127\n",
      "[2,  4500] loss: 0.140\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.705\n",
      "[3,  1000] loss: 0.287\n",
      "[3,  1500] loss: 0.225\n",
      "[3,  2000] loss: 0.135\n",
      "[3,  2500] loss: 0.161\n",
      "[3,  3000] loss: 0.234\n",
      "[3,  3500] loss: 0.127\n",
      "[3,  4000] loss: 0.114\n",
      "[3,  4500] loss: 0.075\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.074\n",
      "[4,  1000] loss: 0.071\n",
      "[4,  1500] loss: 0.079\n",
      "[4,  2000] loss: 0.111\n",
      "[4,  2500] loss: 0.081\n",
      "[4,  3000] loss: 0.088\n",
      "[4,  3500] loss: 0.054\n",
      "[4,  4000] loss: 0.054\n",
      "[4,  4500] loss: 0.071\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.167\n",
      "[5,  1000] loss: 0.104\n",
      "[5,  1500] loss: 0.078\n",
      "[5,  2000] loss: 0.064\n",
      "[5,  2500] loss: 0.054\n",
      "[5,  3000] loss: 0.067\n",
      "[5,  3500] loss: 0.079\n",
      "[5,  4000] loss: 0.074\n",
      "[5,  4500] loss: 0.101\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.136\n",
      "[6,  1000] loss: 0.104\n",
      "[6,  1500] loss: 0.072\n",
      "[6,  2000] loss: 0.046\n",
      "[6,  2500] loss: 0.038\n",
      "[6,  3000] loss: 0.044\n",
      "[6,  3500] loss: 0.028\n",
      "[6,  4000] loss: 0.036\n",
      "[6,  4500] loss: 0.041\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.032\n",
      "[7,  1000] loss: 0.029\n",
      "[7,  1500] loss: 0.017\n",
      "[7,  2000] loss: 0.031\n",
      "[7,  2500] loss: 0.024\n",
      "[7,  3000] loss: 0.023\n",
      "[7,  3500] loss: 0.027\n",
      "[7,  4000] loss: 0.023\n",
      "[7,  4500] loss: 0.016\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.011\n",
      "[8,  1000] loss: 0.012\n",
      "[8,  1500] loss: 0.009\n",
      "[8,  2000] loss: 0.009\n",
      "[8,  2500] loss: 0.008\n",
      "[8,  3000] loss: 0.016\n",
      "[8,  3500] loss: 0.012\n",
      "[8,  4000] loss: 0.006\n",
      "[8,  4500] loss: 0.007\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.008\n",
      "[9,  1000] loss: 0.005\n",
      "[9,  1500] loss: 0.005\n",
      "[9,  2000] loss: 0.011\n",
      "[9,  2500] loss: 0.006\n",
      "[9,  3000] loss: 0.018\n",
      "[9,  3500] loss: 0.010\n",
      "[9,  4000] loss: 0.004\n",
      "[9,  4500] loss: 0.002\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.009\n",
      "[10,  1000] loss: 0.005\n",
      "[10,  1500] loss: 0.014\n",
      "[10,  2000] loss: 0.004\n",
      "[10,  2500] loss: 0.012\n",
      "[10,  3000] loss: 0.004\n",
      "[10,  3500] loss: 0.006\n",
      "[10,  4000] loss: 0.003\n",
      "[10,  4500] loss: 0.005\n",
      "Finished Training\n",
      "Finished Training in: 0:02:44.206954\n",
      "Accuracy of the network on the 1154 test images: 99 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 99 %\n",
      "Started at: 18:10:28\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.391\n",
      "[1,  1500] loss: 1.388\n",
      "[1,  2000] loss: 1.370\n",
      "[1,  2500] loss: 1.026\n",
      "[1,  3000] loss: 0.753\n",
      "[1,  3500] loss: 0.570\n",
      "[1,  4000] loss: 0.500\n",
      "[1,  4500] loss: 0.430\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.437\n",
      "[2,  1000] loss: 0.354\n",
      "[2,  1500] loss: 0.380\n",
      "[2,  2000] loss: 0.338\n",
      "[2,  2500] loss: 0.342\n",
      "[2,  3000] loss: 0.350\n",
      "[2,  3500] loss: 0.388\n",
      "[2,  4000] loss: 0.379\n",
      "[2,  4500] loss: 0.316\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.369\n",
      "[3,  1000] loss: 0.392\n",
      "[3,  1500] loss: 0.342\n",
      "[3,  2000] loss: 0.285\n",
      "[3,  2500] loss: 0.258\n",
      "[3,  3000] loss: 0.258\n",
      "[3,  3500] loss: 0.244\n",
      "[3,  4000] loss: 0.199\n",
      "[3,  4500] loss: 0.295\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.230\n",
      "[4,  1000] loss: 0.226\n",
      "[4,  1500] loss: 0.164\n",
      "[4,  2000] loss: 0.219\n",
      "[4,  2500] loss: 0.194\n",
      "[4,  3000] loss: 0.191\n",
      "[4,  3500] loss: 0.163\n",
      "[4,  4000] loss: 0.387\n",
      "[4,  4500] loss: 0.267\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.216\n",
      "[5,  1000] loss: 0.264\n",
      "[5,  1500] loss: 0.203\n",
      "[5,  2000] loss: 0.188\n",
      "[5,  2500] loss: 0.209\n",
      "[5,  3000] loss: 0.220\n",
      "[5,  3500] loss: 0.215\n",
      "[5,  4000] loss: 0.201\n",
      "[5,  4500] loss: 0.143\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.139\n",
      "[6,  1000] loss: 0.109\n",
      "[6,  1500] loss: 0.134\n",
      "[6,  2000] loss: 0.097\n",
      "[6,  2500] loss: 0.094\n",
      "[6,  3000] loss: 0.092\n",
      "[6,  3500] loss: 0.069\n",
      "[6,  4000] loss: 0.088\n",
      "[6,  4500] loss: 0.082\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.084\n",
      "[7,  1000] loss: 0.059\n",
      "[7,  1500] loss: 0.053\n",
      "[7,  2000] loss: 0.065\n",
      "[7,  2500] loss: 0.059\n",
      "[7,  3000] loss: 0.061\n",
      "[7,  3500] loss: 0.050\n",
      "[7,  4000] loss: 0.055\n",
      "[7,  4500] loss: 0.059\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.057\n",
      "[8,  1000] loss: 0.043\n",
      "[8,  1500] loss: 0.073\n",
      "[8,  2000] loss: 0.075\n",
      "[8,  2500] loss: 0.056\n",
      "[8,  3000] loss: 0.057\n",
      "[8,  3500] loss: 0.057\n",
      "[8,  4000] loss: 0.071\n",
      "[8,  4500] loss: 0.075\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.060\n",
      "[9,  1000] loss: 0.046\n",
      "[9,  1500] loss: 0.022\n",
      "[9,  2000] loss: 0.068\n",
      "[9,  2500] loss: 0.055\n",
      "[9,  3000] loss: 0.045\n",
      "[9,  3500] loss: 0.057\n",
      "[9,  4000] loss: 0.039\n",
      "[9,  4500] loss: 0.048\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.036\n",
      "[10,  1000] loss: 0.036\n",
      "[10,  1500] loss: 0.027\n",
      "[10,  2000] loss: 0.059\n",
      "[10,  2500] loss: 0.030\n",
      "[10,  3000] loss: 0.052\n",
      "[10,  3500] loss: 0.030\n",
      "[10,  4000] loss: 0.041\n",
      "[10,  4500] loss: 0.025\n",
      "Finished Training\n",
      "Finished Training in: 0:02:01.777306\n",
      "Accuracy of the network on the 1154 test images: 98 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 93 %\n",
      "Started at: 18:12:36\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.389\n",
      "[1,  1000] loss: 1.386\n",
      "[1,  1500] loss: 1.385\n",
      "[1,  2000] loss: 1.348\n",
      "[1,  2500] loss: 0.995\n",
      "[1,  3000] loss: 0.562\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.431\n",
      "[2,  1000] loss: 0.432\n",
      "[2,  1500] loss: 0.325\n",
      "[2,  2000] loss: 0.258\n",
      "[2,  2500] loss: 0.263\n",
      "[2,  3000] loss: 0.436\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.173\n",
      "[3,  1000] loss: 0.181\n",
      "[3,  1500] loss: 0.168\n",
      "[3,  2000] loss: 0.171\n",
      "[3,  2500] loss: 0.175\n",
      "[3,  3000] loss: 0.220\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.112\n",
      "[4,  1000] loss: 0.071\n",
      "[4,  1500] loss: 0.101\n",
      "[4,  2000] loss: 0.109\n",
      "[4,  2500] loss: 0.145\n",
      "[4,  3000] loss: 0.090\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.068\n",
      "[5,  1000] loss: 0.135\n",
      "[5,  1500] loss: 0.191\n",
      "[5,  2000] loss: 0.108\n",
      "[5,  2500] loss: 0.076\n",
      "[5,  3000] loss: 0.063\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.046\n",
      "[6,  1000] loss: 0.045\n",
      "[6,  1500] loss: 0.041\n",
      "[6,  2000] loss: 0.043\n",
      "[6,  2500] loss: 0.039\n",
      "[6,  3000] loss: 0.051\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.039\n",
      "[7,  1000] loss: 0.023\n",
      "[7,  1500] loss: 0.038\n",
      "[7,  2000] loss: 0.025\n",
      "[7,  2500] loss: 0.017\n",
      "[7,  3000] loss: 0.019\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.022\n",
      "[8,  1000] loss: 0.020\n",
      "[8,  1500] loss: 0.012\n",
      "[8,  2000] loss: 0.013\n",
      "[8,  2500] loss: 0.033\n",
      "[8,  3000] loss: 0.027\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.033\n",
      "[9,  1000] loss: 0.019\n",
      "[9,  1500] loss: 0.008\n",
      "[9,  2000] loss: 0.012\n",
      "[9,  2500] loss: 0.015\n",
      "[9,  3000] loss: 0.009\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.018\n",
      "[10,  1000] loss: 0.013\n",
      "[10,  1500] loss: 0.019\n",
      "[10,  2000] loss: 0.013\n",
      "[10,  2500] loss: 0.010\n",
      "[10,  3000] loss: 0.027\n",
      "Finished Training\n",
      "Finished Training in: 0:02:01.798464\n",
      "Accuracy of the network on the 1154 test images: 99 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 98 %\n",
      "Started at: 18:14:45\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.389\n",
      "[1,  1000] loss: 1.387\n",
      "[1,  1500] loss: 1.387\n",
      "[1,  2000] loss: 1.377\n",
      "[1,  2500] loss: 1.138\n",
      "[1,  3000] loss: 0.697\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.540\n",
      "[2,  1000] loss: 0.415\n",
      "[2,  1500] loss: 0.396\n",
      "[2,  2000] loss: 0.362\n",
      "[2,  2500] loss: 0.371\n",
      "[2,  3000] loss: 0.404\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.333\n",
      "[3,  1000] loss: 0.264\n",
      "[3,  1500] loss: 0.317\n",
      "[3,  2000] loss: 0.336\n",
      "[3,  2500] loss: 0.341\n",
      "[3,  3000] loss: 0.333\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.306\n",
      "[4,  1000] loss: 0.292\n",
      "[4,  1500] loss: 0.283\n",
      "[4,  2000] loss: 0.245\n",
      "[4,  2500] loss: 0.235\n",
      "[4,  3000] loss: 0.301\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.208\n",
      "[5,  1000] loss: 0.315\n",
      "[5,  1500] loss: 0.292\n",
      "[5,  2000] loss: 0.425\n",
      "[5,  2500] loss: 0.300\n",
      "[5,  3000] loss: 0.227\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.122\n",
      "[6,  1000] loss: 0.161\n",
      "[6,  1500] loss: 0.115\n",
      "[6,  2000] loss: 0.135\n",
      "[6,  2500] loss: 0.176\n",
      "[6,  3000] loss: 0.141\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.160\n",
      "[7,  1000] loss: 0.130\n",
      "[7,  1500] loss: 0.115\n",
      "[7,  2000] loss: 0.116\n",
      "[7,  2500] loss: 0.098\n",
      "[7,  3000] loss: 0.095\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.081\n",
      "[8,  1000] loss: 0.126\n",
      "[8,  1500] loss: 0.140\n",
      "[8,  2000] loss: 0.093\n",
      "[8,  2500] loss: 0.100\n",
      "[8,  3000] loss: 0.116\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.103\n",
      "[9,  1000] loss: 0.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  1500] loss: 0.088\n",
      "[9,  2000] loss: 0.068\n",
      "[9,  2500] loss: 0.090\n",
      "[9,  3000] loss: 0.091\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.086\n",
      "[10,  1000] loss: 0.115\n",
      "[10,  1500] loss: 0.111\n",
      "[10,  2000] loss: 0.094\n",
      "[10,  2500] loss: 0.087\n",
      "[10,  3000] loss: 0.098\n",
      "Finished Training\n",
      "Finished Training in: 0:01:31.570564\n",
      "Accuracy of the network on the 1154 test images: 96 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 90 %\n",
      "Started at: 18:16:22\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.389\n",
      "[1,  1000] loss: 1.387\n",
      "[1,  1500] loss: 1.386\n",
      "[1,  2000] loss: 1.315\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.601\n",
      "[2,  1000] loss: 0.454\n",
      "[2,  1500] loss: 0.374\n",
      "[2,  2000] loss: 0.368\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.363\n",
      "[3,  1000] loss: 0.343\n",
      "[3,  1500] loss: 0.223\n",
      "[3,  2000] loss: 0.316\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.169\n",
      "[4,  1000] loss: 0.178\n",
      "[4,  1500] loss: 0.187\n",
      "[4,  2000] loss: 0.240\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.124\n",
      "[5,  1000] loss: 0.184\n",
      "[5,  1500] loss: 0.152\n",
      "[5,  2000] loss: 0.156\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.067\n",
      "[6,  1000] loss: 0.052\n",
      "[6,  1500] loss: 0.031\n",
      "[6,  2000] loss: 0.063\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.065\n",
      "[7,  1000] loss: 0.037\n",
      "[7,  1500] loss: 0.018\n",
      "[7,  2000] loss: 0.024\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.029\n",
      "[8,  1000] loss: 0.035\n",
      "[8,  1500] loss: 0.026\n",
      "[8,  2000] loss: 0.033\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.040\n",
      "[9,  1000] loss: 0.020\n",
      "[9,  1500] loss: 0.022\n",
      "[9,  2000] loss: 0.024\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.012\n",
      "[10,  1000] loss: 0.033\n",
      "[10,  1500] loss: 0.014\n",
      "[10,  2000] loss: 0.039\n",
      "Finished Training\n",
      "Finished Training in: 0:01:22.079878\n",
      "Accuracy of the network on the 1154 test images: 99 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 99 %\n",
      "Started at: 18:17:50\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.389\n",
      "[1,  1000] loss: 1.388\n",
      "[1,  1500] loss: 1.388\n",
      "[1,  2000] loss: 1.367\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 0.808\n",
      "[2,  1000] loss: 0.682\n",
      "[2,  1500] loss: 0.477\n",
      "[2,  2000] loss: 0.444\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.407\n",
      "[3,  1000] loss: 0.363\n",
      "[3,  1500] loss: 0.373\n",
      "[3,  2000] loss: 0.371\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.357\n",
      "[4,  1000] loss: 0.285\n",
      "[4,  1500] loss: 0.273\n",
      "[4,  2000] loss: 0.269\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.245\n",
      "[5,  1000] loss: 0.339\n",
      "[5,  1500] loss: 0.322\n",
      "[5,  2000] loss: 0.247\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.238\n",
      "[6,  1000] loss: 0.199\n",
      "[6,  1500] loss: 0.190\n",
      "[6,  2000] loss: 0.185\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.182\n",
      "[7,  1000] loss: 0.163\n",
      "[7,  1500] loss: 0.137\n",
      "[7,  2000] loss: 0.161\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.090\n",
      "[8,  1000] loss: 0.131\n",
      "[8,  1500] loss: 0.139\n",
      "[8,  2000] loss: 0.116\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.127\n",
      "[9,  1000] loss: 0.130\n",
      "[9,  1500] loss: 0.127\n",
      "[9,  2000] loss: 0.112\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.119\n",
      "[10,  1000] loss: 0.084\n",
      "[10,  1500] loss: 0.083\n",
      "[10,  2000] loss: 0.114\n",
      "Finished Training\n",
      "Finished Training in: 0:01:02.109954\n",
      "Accuracy of the network on the 1154 test images: 88 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 82 %\n",
      "Started at: 18:18:57\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.384\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.380\n",
      "[2,  1000] loss: 1.219\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.690\n",
      "[3,  1000] loss: 0.453\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.358\n",
      "[4,  1000] loss: 0.382\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.321\n",
      "[5,  1000] loss: 0.325\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.215\n",
      "[6,  1000] loss: 0.138\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.118\n",
      "[7,  1000] loss: 0.111\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.116\n",
      "[8,  1000] loss: 0.078\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.085\n",
      "[9,  1000] loss: 0.047\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.056\n",
      "[10,  1000] loss: 0.073\n",
      "Finished Training\n",
      "Finished Training in: 0:00:41.183597\n",
      "Accuracy of the network on the 1154 test images: 97 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 97 %\n",
      "Started at: 18:19:44\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "[1,  1000] loss: 1.384\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.384\n",
      "[2,  1000] loss: 1.231\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 0.756\n",
      "[3,  1000] loss: 0.704\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 0.447\n",
      "[4,  1000] loss: 0.395\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.426\n",
      "[5,  1000] loss: 0.424\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.330\n",
      "[6,  1000] loss: 0.280\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.267\n",
      "[7,  1000] loss: 0.251\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.252\n",
      "[8,  1000] loss: 0.217\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.244\n",
      "[9,  1000] loss: 0.200\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.209\n",
      "[10,  1000] loss: 0.209\n",
      "Finished Training\n",
      "Finished Training in: 0:00:30.574666\n",
      "Accuracy of the network on the 1154 test images: 91 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 87 %\n",
      "Started at: 18:20:19\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.390\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.391\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 1.385\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 1.110\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.757\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.540\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.345\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.279\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.277\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.224\n",
      "Finished Training\n",
      "Finished Training in: 0:00:20.412612\n",
      "Accuracy of the network on the 1154 test images: 93 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 95 %\n",
      "Started at: 18:20:45\n",
      "== Starting epoch 0 ==\n",
      "[1,   500] loss: 1.391\n",
      "== Starting epoch 1 ==\n",
      "[2,   500] loss: 1.392\n",
      "== Starting epoch 2 ==\n",
      "[3,   500] loss: 1.391\n",
      "== Starting epoch 3 ==\n",
      "[4,   500] loss: 1.371\n",
      "== Starting epoch 4 ==\n",
      "[5,   500] loss: 0.949\n",
      "== Starting epoch 5 ==\n",
      "[6,   500] loss: 0.773\n",
      "== Starting epoch 6 ==\n",
      "[7,   500] loss: 0.539\n",
      "== Starting epoch 7 ==\n",
      "[8,   500] loss: 0.392\n",
      "== Starting epoch 8 ==\n",
      "[9,   500] loss: 0.365\n",
      "== Starting epoch 9 ==\n",
      "[10,   500] loss: 0.297\n",
      "Finished Training\n",
      "Finished Training in: 0:00:15.089308\n",
      "Accuracy of the network on the 1154 test images: 79 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 81 %\n",
      "Started at: 18:21:04\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:10.314795\n",
      "Accuracy of the network on the 1154 test images: 5 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 5 %\n",
      "Started at: 18:21:19\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:07.550870\n",
      "Accuracy of the network on the 1154 test images: 5 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 5 %\n",
      "Started at: 18:21:31\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:02.000567\n",
      "Accuracy of the network on the 1154 test images: 31 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 31 %\n",
      "Started at: 18:21:38\n",
      "== Starting epoch 0 ==\n",
      "== Starting epoch 1 ==\n",
      "== Starting epoch 2 ==\n",
      "== Starting epoch 3 ==\n",
      "== Starting epoch 4 ==\n",
      "== Starting epoch 5 ==\n",
      "== Starting epoch 6 ==\n",
      "== Starting epoch 7 ==\n",
      "== Starting epoch 8 ==\n",
      "== Starting epoch 9 ==\n",
      "Finished Training\n",
      "Finished Training in: 0:00:01.588122\n",
      "Accuracy of the network on the 1154 test images: 31 %\n",
      "Accuracy of the network on the 1154 randomly rotated test images: 31 %\n"
     ]
    }
   ],
   "source": [
    "data_usage = [0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.01]\n",
    "\n",
    "\n",
    "for data_proportion in data_usage:\n",
    "\n",
    "    cycnn = CyNet(data='CAP', random_rotate=False)\n",
    "    train(cycnn, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500, train_proportion=data_proportion)\n",
    "    test(cycnn, 'CAP')\n",
    "    \n",
    "    cnn = CNN(data='CAP', random_rotate=False)\n",
    "    train(cnn, 'CAP', 10, lrs=[(0, 0.001), (5, 0.0001)], momentum=0.9, print_interval=500, train_proportion=data_proportion)\n",
    "    test(cnn, 'CAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
